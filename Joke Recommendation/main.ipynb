{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import sklearn as sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn import cross_validation as cv\n",
    "import statistics\n",
    "\n",
    "def loadTrainFile():\n",
    "    userID = []\n",
    "    itemID = []\n",
    "    rating = []\n",
    "    with open(\"train.csv\") as f:\n",
    "        for i,line in enumerate(f):\n",
    "            if(i>0):\n",
    "                row = line.strip().split(',')\n",
    "                \n",
    "                if(row[2]!='99.0'):\n",
    "                    userID.append(round(float(row[0])))\n",
    "                    itemID.append(round(float(row[1])))\n",
    "                    rating.append(float(row[2]))\n",
    "                \n",
    "    return userID, itemID, rating\n",
    "\n",
    "def loadTestFile():\n",
    "    userID = []\n",
    "    itemID = []\n",
    "    with open(\"test.csv\") as f:\n",
    "        for i,line in enumerate(f):\n",
    "            if(i>0):\n",
    "                row = line.strip().split(',')\n",
    "                userID.append(round(float(row[0])))\n",
    "                itemID.append(round(float(row[1])))\n",
    "                \n",
    "    return userID, itemID\n",
    "\n",
    "\n",
    "#############Data#############\n",
    "train_userID, train_itemID, train_rating = loadTrainFile()\n",
    "test_userID, test_itemID = loadTestFile()\n",
    "\n",
    "train_data, test_data = cv.train_test_split(df, test_size=0.25)\n",
    "\n",
    "#############User-User#############\n",
    "user_item_ratings = np.zeros([10000,100])\n",
    "user_item_has_ratings = np.full([10000,100], False)\n",
    "for i, r in enumerate(train_rating):\n",
    "    user_item_ratings[train_userID[i]-1][train_itemID[i]-1]=r\n",
    "    user_item_has_ratings[train_userID[i]-1][train_itemID[i]-1]=True\n",
    "\n",
    "for i,ratings in enumerate(user_item_ratings):\n",
    "    n = user_item_has_ratings[i].tolist().count(True)\n",
    "    mean = ratings.sum()/n\n",
    "    for j in range(len(ratings)):\n",
    "        if(user_item_has_ratings[i][j]):\n",
    "            user_item_ratings[i][j]-=mean\n",
    "print(user_item_ratings)\n",
    "print(user_item_ratings.sum(axis=1))\n",
    "print(user_item_has_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_similarity = np.full([10000,10000],1)\n",
    "user_similarity = user_similarity-pairwise_distances(user_item_ratings, metric='cosine')\n",
    "print(user_similarity)\n",
    "user_similar_userID = []\n",
    "sort_index = np.argsort(-user_similarity,axis=1)\n",
    "print(sort_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output=[['user_id-item_id','rating']]\n",
    "for i in range(len(test_userID)):\n",
    "    user_idx = test_userID[i]-1\n",
    "    item_idx = test_itemID[i]-1\n",
    "    n = 0\n",
    "    similarity_sum = 0.0\n",
    "    weighted_rate = 0.0\n",
    "    for neighbor in sort_index[user_idx]:\n",
    "        if(neighbor == user_idx and user_item_has_ratings[user_idx][item_idx]):\n",
    "            value = user_item_ratings[user_idx][item_idx]\n",
    "            break\n",
    "        if(user_item_has_ratings[neighbor][item_idx]):\n",
    "            weighted_rate += user_item_ratings[neighbor][item_idx]*user_similarity[user_idx][neighbor]\n",
    "            similarity_sum += abs(user_similarity[user_idx][neighbor])\n",
    "            n+=1\n",
    "            if(n==10):\n",
    "                weighted_rate /= similarity_sum\n",
    "                break\n",
    "            \n",
    "    entry = str(test_userID[i])+'-'+str(test_itemID[i])\n",
    "    value = weighted_rate\n",
    "    test_output.append([entry,value])\n",
    "np.savetxt(\"output.csv\", np.array(test_output, dtype=np.str), fmt='%s,%s', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loadTrainFile' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f82fbc12cdba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#############Item-Item#############\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_userID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_itemID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_rating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadTrainFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_userID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_itemID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadTestFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mitem_user_ratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loadTrainFile' is not defined"
     ]
    }
   ],
   "source": [
    "#############Item-Item#############\n",
    "train_userID, train_itemID, train_rating = loadTrainFile()\n",
    "test_userID, test_itemID = loadTestFile()\n",
    " \n",
    "item_user_ratings = np.zeros([100,10000])\n",
    "item_user_has_ratings = np.full([100,10000], False)\n",
    "for i, r in enumerate(train_rating):\n",
    "    item_user_ratings[train_itemID[i]-1][train_userID[i]-1]=r\n",
    "    item_user_has_ratings[train_itemID[i]-1][train_userID[i]-1]=True\n",
    "\n",
    "#minus mean\n",
    "item_mean = np.zeros([100])\n",
    "for i,ratings in enumerate(item_user_ratings):\n",
    "    n = item_user_has_ratings[i].tolist().count(True)\n",
    "    mean = ratings.sum()/n\n",
    "    item_mean[i] = mean\n",
    "    for j in range(len(ratings)):\n",
    "        if(item_user_has_ratings[i][j]):\n",
    "            item_user_ratings[i][j]-=mean\n",
    "print(\"item_user_ratings\")\n",
    "print(item_user_ratings)\n",
    "print(item_user_ratings.sum(axis=1))\n",
    "print(item_user_has_ratings)\n",
    "\n",
    "item_similarity = np.full([100,100],1)\n",
    "item_similarity = item_similarity-pairwise_distances(item_user_ratings, metric='cosine')\n",
    "print(\"item_similarity\")\n",
    "print(item_similarity)\n",
    "sort_index = np.argsort(-item_similarity,axis=1)\n",
    "print(sort_index)\n",
    "print(item_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output=[['user_id-item_id','rating']]\n",
    "for i in range(len(test_userID)):\n",
    "    user_idx = test_userID[i]-1\n",
    "    item_idx = test_itemID[i]-1\n",
    "    n = 0\n",
    "    similarity_sum = 0.0\n",
    "    weighted_rate = 0.0\n",
    "#     print('user_idx ', user_idx, 'item_idx ', item_idx)\n",
    "    if(item_user_has_ratings[item_idx][user_idx]):\n",
    "        value = item_user_ratings[item_idx][user_idx]\n",
    "    else:\n",
    "        for neighbor in sort_index[item_idx]:\n",
    "            if(item_user_has_ratings[neighbor][user_idx]):\n",
    "#                 print('neighbor ', neighbor, 'sim=', item_similarity[item_idx][neighbor])\n",
    "                weighted_rate += item_user_ratings[neighbor][user_idx]*item_similarity[item_idx][neighbor]\n",
    "                similarity_sum += abs(item_similarity[item_idx][neighbor])\n",
    "                n+=1\n",
    "            if(n==15 or item_similarity[item_idx][neighbor]< 0):\n",
    "                weighted_rate /= similarity_sum\n",
    "                value = weighted_rate\n",
    "                break\n",
    "\n",
    "    entry = str(test_userID[i])+'-'+str(test_itemID[i])\n",
    "    test_output.append([entry,value])\n",
    "np.savetxt(\"output.csv\", np.array(test_output, dtype=np.str), fmt='%s,%s', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "joke_ratings = np.full([100, 10000], 99)\n",
    "for i, r in enumerate(rating):\n",
    "    joke_ratings[itemID[i]-1][userID[i]-1]=r\n",
    "\n",
    "joke_mean_ratings = np.zeros([100])\n",
    "joke_people_num = np.zeros([100], dtype=int)\n",
    "for i, per_joke_ratings in enumerate(joke_ratings):\n",
    "    m = 0\n",
    "    n = 0\n",
    "    for score in per_joke_ratings:\n",
    "        if(score!=99):\n",
    "            m+=score\n",
    "            n+=1\n",
    "    m/=n\n",
    "    joke_mean_ratings[i]=m\n",
    "    joke_people_num[i]=n\n",
    "\n",
    "print(joke_mean_ratings)\n",
    "\n",
    "users_vec = np.zeros([10000,100])\n",
    "for i,vec in enumerate(users_vec):\n",
    "    users_vec[i] = joke_mean_ratings\n",
    "\n",
    "for i, r in enumerate(rating):\n",
    "    users_vec[userID[i]-1][itemID[i]-1]=r\n",
    "print(users_vec)\n",
    "\n",
    "\n",
    "# plt.hist(joke_ratings[6], bins =  [-10,-8,-6,-4,-2,0,2,4,6,8,10]) \n",
    "# plt.title(\"joke7\") \n",
    "# plt.show()\n",
    "\n",
    "# plt.hist(joke_ratings[99], bins =  [-10,-8,-6,-4,-2,0,2,4,6,8,10]) \n",
    "# plt.title(\"joke 100\") \n",
    "# plt.show()\n",
    "\n",
    "# plt.hist(joke_mean_ratings, bins =  [-10,-8,-6,-4,-2,0,2,4,6,8,10]) \n",
    "# plt.title(\"histogram\") \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "def pca(X):\n",
    "    #Standardize the data (mean = 0 and variance = 1)\n",
    "    X_std = preprocessing.scale(X, with_mean=False)\n",
    "\n",
    "    # Calculate covariance matrix\n",
    "    covariance_matrix = np.cov(np.transpose(X_std))\n",
    "\n",
    "    # Calculate the eigenvectors and eigenvalues of the covariave matrix\n",
    "    eig_val, eig_vec = np.linalg.eig(covariance_matrix)\n",
    "\n",
    "    # Sort eig_value based on eig_val from highest to lowest\n",
    "    abs_eig_val = np.abs(eig_val)\n",
    "    indices = np.argsort(-abs_eig_val)\n",
    "    abs_eig_val = abs_eig_val[indices]\n",
    "    \n",
    "    # Find top K eigen values that cover 85% variance\n",
    "    K = abs_eig_val.shape[0]-1\n",
    "    eig_sum = 0\n",
    "    for i in range(abs_eig_val.shape[0]):\n",
    "        eig_sum = eig_sum+abs_eig_val[i]\n",
    "    #print(\"sum of eig value: \", eig_sum)\n",
    "\n",
    "    eig_val_percent = abs_eig_val/eig_sum\n",
    "\n",
    "    eig_percent_sum = 0\n",
    "    for i in range(eig_val.shape[0]):\n",
    "        eig_percent_sum = eig_percent_sum+eig_val_percent[i]\n",
    "        if eig_percent_sum>=0.70:\n",
    "            K = i\n",
    "            print(\"K: \", K,\" %=\", eig_percent_sum)\n",
    "            break\n",
    "\n",
    "    eig_vec = eig_vec[indices]\n",
    "\n",
    "    eig_pairs = [(abs_eig_val[i], eig_vec[:,i]) for i in range(abs_eig_val.shape[0])]\n",
    "    #print(eig_pairs)\n",
    "\n",
    "    # Select the top K eig_vec\n",
    "    selected_feature=np.array([ele[1] for ele in eig_pairs[:K]])\n",
    "\n",
    "    # Get new data: Project original data to new dimension\n",
    "    project_matrix = np.transpose(selected_feature)\n",
    "    data=np.dot(X_std, project_matrix)\n",
    "    # print(\"X_std.shape\", X_std.shape, \"project_matrix.shape\", project_matrix.shape, \"After PCA X shape: \", data.shape)\n",
    "    return data\n",
    "\n",
    "pca_X = pca(users_vec)\n",
    "print(pca_X.shape)\n",
    "\n",
    "plt.scatter(pca_X[:,0], pca_X[:,1], alpha=0.6)  # 绘制散点图，透明度为0.6（这样颜色浅一点，比较好看）\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "\n",
    "neigh = NearestNeighbors(5)\n",
    "neigh.fit(pca_X)\n",
    "\n",
    "\n",
    "output_rating = np.full_like(test_userID, 0)\n",
    "test_user_vec = pca_X[np.array(test_userID)-1]\n",
    "test_user_vec_neighbors = neigh.kneighbors(test_user_vec, 5, return_distance=False)\n",
    "print(test_user_vec_neighbors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.mean(users_vec[test_user_vec_neighbors[0]],axis=0)[0])\n",
    "for i,user_neighbor in enumerate(test_user_vec_neighbors):\n",
    "    m=np.mean(users_vec[user_neighbor], axis=0)[test_itemID[i]-1]\n",
    "    output_rating[i]=m\n",
    "print(output_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output=[['user_id-item_id','rating']]\n",
    "for i in range(len(test_userID)):\n",
    "    entry=str(test_userID[i])+'-'+str(test_itemID[i])\n",
    "    value=output_rating[i]\n",
    "    test_output.append([entry,value])\n",
    "np.savetxt(\"output.csv\", np.array(test_output, dtype=np.str), fmt='%s,%s', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-virtualenv-tensorflow",
   "language": "python",
   "name": "my-virtualenv-tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
