{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean/tensorflow/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing #标准化数据模块\n",
    "########## Hyperparameter ##########\n",
    "BATCH_SIZE = 5\n",
    "EPOCH_BOUND = 1000\n",
    "EARLY_STOP_CHECK_EPOCH = 100\n",
    "TAKE_CROSS_VALIDATION = True\n",
    "LEARNING_RATE = 0.01\n",
    "CROSS_VALIDATION = 10\n",
    "########## Hyperparameter ##########\n",
    "\n",
    "def loadTrainFile():\n",
    "    tmp = np.loadtxt(\"train.csv\", dtype=np.str, delimiter=\",\")\n",
    "    userID = tmp[1:,0].astype(int)\n",
    "    item1 = tmp[1:,1].astype(int)\n",
    "    item2 = tmp[1:,2].astype(int)\n",
    "    labels = tmp[1:,3].astype(int)\n",
    "    return userID, item1, item2, labels\n",
    "def loadTestFile():\n",
    "    tmp = np.loadtxt(\"test.csv\", dtype=np.str, delimiter=\",\")\n",
    "    userID = tmp[1:,0].astype(int)\n",
    "    item1 = tmp[1:,1].astype(int)\n",
    "    item2 = tmp[1:,2].astype(int)\n",
    "    return userID, item1, item2\n",
    "def loadUserFile():\n",
    "    tmp = np.loadtxt(\"users.csv\", dtype=str, delimiter=\",\")\n",
    "    return tmp[1:,1:]\n",
    "\n",
    "def loadItemFile():\n",
    "    tmp = np.loadtxt(\"items.csv\", dtype=np.str, delimiter=\",\")\n",
    "    return tmp[1:,1:]\n",
    "\n",
    "def dnn(x):\n",
    "    dense1 = tf.layers.dense(\n",
    "        inputs=x,\n",
    "        units=16,\n",
    "        activation=tf.nn.relu,\n",
    "        name='dense1'\n",
    "    )\n",
    "    dense2 = tf.layers.dense(\n",
    "        inputs=dense1,\n",
    "        units=8,\n",
    "        activation=tf.nn.relu,\n",
    "        name='dense2'\n",
    "    )\n",
    "    dense3 = tf.layers.dense(\n",
    "        inputs=dense2,\n",
    "        units=8,\n",
    "        activation=tf.nn.relu,\n",
    "        name='dense3'\n",
    "    )\n",
    "    dense4 = tf.layers.dense(\n",
    "        inputs=dense3,\n",
    "        units=4,\n",
    "        activation=tf.nn.relu,\n",
    "        name='dense4'\n",
    "    )\n",
    "    logits = tf.layers.dense(inputs=dense4, units=1, name='logits')\n",
    "    \n",
    "    return logits\n",
    "\n",
    "# split dataset into training set and one validation set\n",
    "def split_folds(indices, Inputs, Labels, cross_validation, fold):\n",
    "    n = Inputs.shape[0]\n",
    "    if fold == cross_validation:\n",
    "        validation_size = n - (int(n/cross_validation) * (cross_validation-1))\n",
    "        X_train_idx, X_validate_idx = indices[:(n-validation_size)], indices[(n-validation_size):]\n",
    "        y_train_idx, y_validate_idx = indices[:(n-validation_size)], indices[(n-validation_size):]\n",
    "    else:\n",
    "        validation_size = int(n/cross_validation)\n",
    "        X_train_idx, X_validate_idx = np.concatenate((indices[:validation_size*(fold-1)], indices[validation_size*fold:]), axis=0), indices[(validation_size*(fold-1)):(validation_size*fold)]\n",
    "        y_train_idx, y_validate_idx = np.concatenate((indices[:validation_size*(fold-1)], indices[validation_size*fold:]), axis=0), indices[(validation_size*(fold-1)):(validation_size*fold)]\n",
    "    X_train, X_validate = np.array(Inputs[X_train_idx,:]), np.array(Inputs[X_validate_idx,:])\n",
    "    y_train, y_validate = np.array(Labels[y_train_idx]), np.array(Labels[y_validate_idx])\n",
    "    return X_train, y_train, X_validate, y_validate\n",
    "\n",
    "def train(X_train, y_train, X_validate, y_validate, optimizer, epoch_bound, stop_threshold, batch_size, testing=False):\n",
    "\n",
    "    global saver\n",
    "    global loss\n",
    "    \n",
    "    early_stop = 0\n",
    "    winner_loss = np.infty\n",
    "    \n",
    "    for epoch in range(epoch_bound):\n",
    "\n",
    "        # randomize training set\n",
    "        indices_training = np.random.permutation(X_train.shape[0])\n",
    "        X_train, y_train = X_train[indices_training,:], y_train[indices_training]\n",
    "\n",
    "        # split training set into multiple mini-batches and start training\n",
    "        total_batches = int(X_train.shape[0] / batch_size)\n",
    "        for batch in range(total_batches):\n",
    "            if batch == total_batches - 1:\n",
    "                sess.run(optimizer, feed_dict={x: X_train[batch*batch_size:], \n",
    "                                               y: y_train[batch*batch_size:]})\n",
    "            else:\n",
    "                sess.run(optimizer, feed_dict={x: X_train[batch*batch_size : (batch+1)*batch_size], \n",
    "                                               y: y_train[batch*batch_size : (batch+1)*batch_size]})\n",
    "        \n",
    "        # validating\n",
    "        cur_loss = 0.0\n",
    "        total_batches = int(X_validate.shape[0] / batch_size)\n",
    "        cur_loss = sess.run(loss, feed_dict={x:X_validate,\n",
    "                                             y:y_validate})\n",
    "#         print('Loss: ', cur_loss)\n",
    "        # If the accuracy rate does not increase for many times, it will early stop epochs-loop \n",
    "        if cur_loss < winner_loss:\n",
    "            early_stop = 0\n",
    "            winner_loss = cur_loss\n",
    "            \n",
    "            save_path = saver.save(sess, \"./saved_model/dnn.ckpt\")\n",
    "        else:\n",
    "            early_stop += 1\n",
    "        if early_stop == stop_threshold:\n",
    "            break\n",
    "    \n",
    "    saver.restore(sess, \"./saved_model/dnn.ckpt\")\n",
    "#     winner_accuracy = sess.run(accuracy, feed_dict={x:X_validate,\n",
    "#                                                     y:y_validate})\n",
    "    return winner_loss, epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.72166713  1.47393266  0.97112381 ... -1.22474487 -1.28527737\n",
      "   0.81649658]\n",
      " [ 0.72166713  1.47393266  0.97112381 ...  0.81649658  1.33773767\n",
      "  -1.22474487]\n",
      " [ 0.72166713  1.47393266  0.97112381 ... -1.22474487  0.46339932\n",
      "   0.81649658]\n",
      " ...\n",
      " [ 0.72166713 -0.34948919  0.97112381 ...  0.81649658 -1.28527737\n",
      "  -1.22474487]\n",
      " [ 0.72166713 -0.34948919  0.97112381 ...  0.81649658 -0.41093902\n",
      "   0.81649658]\n",
      " [ 0.72166713 -0.34948919  0.97112381 ...  0.81649658  0.46339932\n",
      "   0.81649658]]\n",
      "[-0.19324699 -0.83740361  1.73922289  0.45090964  1.09506626 -0.83740361\n",
      " -1.48156024 -0.83740361 -0.19324699  1.09506626  0.37907125 -0.16245911\n",
      "  1.46213197 -0.70398947 -0.70398947 -0.70398947  2.00366234 -0.70398947\n",
      "  0.37907125 -1.24551983 -0.60547036  1.25751537 -0.13972393 -0.60547036\n",
      " -1.0712168   0.3260225   2.18900823  0.3260225  -0.60547036 -1.0712168\n",
      "  0.41758499 -0.77551498  2.20723495  0.41758499  0.41758499 -1.37206497\n",
      " -0.178965   -1.37206497  0.41758499 -0.178965   -0.22298824  0.5203059\n",
      "  0.5203059  -1.70957654  1.26360005  0.5203059  -0.22298824  1.26360005\n",
      " -0.22298824 -1.70957654  0.49374193 -0.9169493   1.90443316 -0.21160368\n",
      "  1.19908755 -0.21160368 -1.62229492 -0.9169493  -0.21160368  0.49374193\n",
      " -0.16744367 -0.72558924  2.06513862  0.3907019   0.94884747 -1.28373482\n",
      "  0.3907019  -1.28373482  0.3907019  -0.72558924  0.47087096 -0.87447463\n",
      " -0.20180184 -0.87447463  1.81621654  0.47087096 -0.87447463  1.14354375\n",
      " -1.54714743  0.47087096 -0.17149859  0.68599434  0.68599434  0.68599434\n",
      "  0.68599434 -1.02899151 -1.02899151 -1.88648444 -0.17149859  1.54348727\n",
      " -0.15789474  1.94736842 -1.21052632 -1.21052632 -0.15789474  0.36842105\n",
      "  0.89473684  0.89473684 -1.21052632 -0.15789474  0.3907019   0.94884747\n",
      " -0.72558924 -1.28373482 -0.72558924  0.94884747  1.50699304  0.94884747\n",
      " -1.28373482 -0.72558924 -0.18569534  1.05227358  0.43328912 -1.42366426\n",
      " -0.18569534 -0.8046798   2.2902425  -0.18569534 -0.8046798  -0.18569534\n",
      " -0.72558924 -0.16744367  2.06513862  0.3907019   0.3907019  -1.28373482\n",
      "  0.94884747 -1.28373482  0.3907019  -0.72558924 -0.61885275  0.4125685\n",
      "  1.44398974 -0.10314212 -0.61885275 -1.13456337  1.95970037 -1.13456337\n",
      "  0.4125685  -0.61885275  1.09506626 -1.48156024  1.73922289 -0.19324699\n",
      "  1.09506626 -0.83740361 -0.83740361 -0.19324699 -0.83740361  0.45090964\n",
      "  0.58950634  0.58950634  1.43165827 -0.25264558  1.43165827 -0.25264558\n",
      " -0.25264558 -0.25264558 -1.93694942 -1.0947975  -0.17291713 -0.74930754\n",
      "  2.13264455  0.40347329  0.97986371 -1.32569796 -0.17291713 -1.32569796\n",
      " -0.17291713  0.40347329 -0.72558924 -0.16744367  2.06513862  0.3907019\n",
      "  0.94884747 -1.28373482  0.3907019  -1.28373482  0.3907019  -0.72558924\n",
      " -0.15369466 -1.1783257   1.89556742  0.35862086  0.87093638 -1.1783257\n",
      "  0.87093638 -1.1783257   0.35862086 -0.66601018  1.26360005 -0.96628239\n",
      "  1.26360005 -0.22298824  1.26360005 -0.22298824 -0.22298824  0.5203059\n",
      " -1.70957654 -0.96628239 -0.15789474  1.42105263 -0.68421053 -1.21052632\n",
      " -0.68421053  0.89473684  1.42105263  0.89473684 -1.21052632 -0.68421053\n",
      " -0.83740361 -0.19324699  2.38337952  0.45090964  0.45090964 -0.83740361\n",
      " -0.19324699 -1.48156024 -0.19324699  0.45090964  1.14354375 -0.20180184\n",
      " -0.20180184 -0.87447463  1.14354375  0.47087096 -1.54714743  1.14354375\n",
      " -1.54714743  0.47087096 -0.16744367 -0.72558924  2.06513862  0.3907019\n",
      "  0.94884747 -1.28373482  0.3907019  -1.28373482  0.3907019  -0.72558924\n",
      "  0.45090964 -0.83740361  2.38337952  0.45090964  0.45090964 -1.48156024\n",
      " -0.19324699 -0.83740361 -0.19324699 -0.19324699  0.36842105 -1.21052632\n",
      "  1.94736842  0.36842105  0.36842105 -0.68421053  0.89473684 -1.21052632\n",
      "  0.36842105 -1.21052632  1.26360005 -0.96628239 -0.96628239 -0.96628239\n",
      "  0.5203059   1.26360005 -0.96628239  1.26360005 -0.96628239  0.5203059\n",
      " -0.61904762  0.80952381  0.80952381 -0.14285714 -1.0952381  -0.61904762\n",
      "  2.23809524 -1.0952381   0.33333333 -0.61904762 -1.37206497  1.61068496\n",
      "  1.01413498  0.41758499 -0.178965   -0.77551498  0.41758499 -1.37206497\n",
      " -0.77551498  1.01413498 -0.13018891 -0.13018891 -0.78113347 -1.43207802\n",
      "  1.82264475  0.52075564  1.1717002  -0.13018891  0.52075564 -1.43207802\n",
      "  1.19908755 -1.62229492  1.90443316 -0.9169493   0.49374193 -0.9169493\n",
      " -0.21160368 -0.21160368 -0.21160368  0.49374193 -0.69748583 -0.11624764\n",
      "  1.62746694  0.46499055  1.62746694 -1.27872403 -0.11624764 -1.27872403\n",
      " -0.69748583  0.46499055 -0.58079717  0.75950399  1.20627104 -0.13403012\n",
      " -1.02756422 -0.13403012  2.09980514 -1.02756422 -0.13403012 -1.02756422\n",
      " -0.12038585 -0.72231512  2.28733121 -0.12038585  0.48154341 -0.72231512\n",
      "  1.08347268 -0.72231512 -0.12038585 -1.32424438  0.57142857 -1.57142857\n",
      "  1.28571429 -0.14285714  1.28571429  0.57142857 -0.14285714  0.57142857\n",
      " -1.57142857 -0.85714286 -0.17291713 -0.74930754  2.13264455  0.40347329\n",
      "  0.97986371 -1.32569796 -0.17291713 -1.32569796  0.40347329 -0.17291713\n",
      " -0.13678823  1.23109403 -1.04870973 -1.04870973 -0.59274898  0.31917253\n",
      "  2.14301554  0.31917253 -1.04870973 -0.13678823  0.41758499 -0.77551498\n",
      "  2.20723495  0.41758499  0.41758499 -1.37206497 -0.178965   -1.37206497\n",
      "  0.41758499 -0.178965    0.3907019  -1.28373482  2.06513862  0.3907019\n",
      "  0.3907019  -1.28373482  0.3907019  -1.28373482  0.3907019  -0.16744367\n",
      "  1.05227358 -1.42366426  1.67125804 -0.18569534  1.05227358 -1.42366426\n",
      " -0.18569534 -0.8046798   0.43328912 -0.18569534 -0.18569534  0.43328912\n",
      "  2.2902425   0.43328912  0.43328912 -0.8046798  -0.8046798  -0.8046798\n",
      " -1.42366426  0.43328912 -0.64918902  0.84893949  1.84769183  0.34956332\n",
      " -0.64918902 -1.14856519  1.34831566 -1.14856519 -0.14981285 -0.64918902\n",
      "  1.09506626 -1.48156024  1.73922289 -0.19324699  1.09506626 -0.83740361\n",
      " -0.83740361 -0.83740361 -0.19324699  0.45090964  0.3907019   0.94884747\n",
      " -1.28373482 -1.28373482 -0.72558924  0.94884747  1.50699304  0.94884747\n",
      " -0.72558924 -0.72558924 -0.05882353  1.11764706 -0.64705882  0.52941176\n",
      " -1.23529412 -1.23529412  0.52941176  0.52941176  1.70588235 -1.23529412\n",
      "  1.33978769 -1.81265393  0.55167728 -1.02454353  1.33978769 -0.23643312\n",
      " -1.02454353  0.55167728  0.55167728 -0.23643312  1.09506626 -0.83740361\n",
      "  1.09506626 -0.83740361  1.09506626 -0.83740361 -1.48156024  1.09506626\n",
      " -0.83740361  0.45090964 -0.57469577 -0.57469577  2.29878308 -0.57469577\n",
      " -0.09578263 -1.05360891  0.86204366 -1.05360891  0.86204366 -0.09578263\n",
      "  0.41758499  1.01413498 -1.37206497 -1.37206497 -0.77551498  0.41758499\n",
      "  1.61068496  1.01413498 -0.178965   -0.77551498  0.          1.34839972\n",
      "  0.67419986  1.34839972  0.         -1.34839972  0.67419986 -1.34839972\n",
      "  0.         -1.34839972  0.94884747 -1.28373482  2.06513862 -0.72558924\n",
      "  0.3907019  -0.72558924  0.3907019   0.3907019  -0.16744367 -1.28373482\n",
      "  1.14354375 -0.87447463  1.81621654 -0.20180184  1.14354375 -0.20180184\n",
      " -0.87447463 -0.20180184 -1.54714743 -0.20180184  0.41758499 -1.37206497\n",
      "  2.20723495  0.41758499  0.41758499 -1.37206497 -0.178965   -0.77551498\n",
      "  0.41758499 -0.178965   -0.23643312 -1.02454353  1.33978769  0.55167728\n",
      "  1.33978769 -1.02454353 -1.02454353 -1.02454353 -0.23643312  1.33978769\n",
      " -0.16744367 -0.72558924  2.06513862  0.3907019   0.94884747 -1.28373482\n",
      "  0.3907019  -1.28373482  0.3907019  -0.72558924 -0.77551498 -0.77551498\n",
      "  2.20723495  0.41758499  1.01413498 -0.77551498 -0.178965   -1.37206497\n",
      "  0.41758499 -0.178965   -0.63599873  0.42399915  0.42399915 -1.16599767\n",
      " -1.16599767  0.42399915  2.01399597  0.95399809 -0.10599979 -1.16599767\n",
      " -0.14285714 -0.14285714  0.57142857 -0.14285714  2.71428571 -0.14285714\n",
      " -0.85714286 -0.14285714 -0.85714286 -0.85714286 -0.09805807 -0.09805807\n",
      " -1.07863874 -1.07863874  0.39223227  0.88252261 -0.09805807  2.35339362\n",
      " -1.07863874 -0.09805807 -0.75       -0.125       0.5         0.5\n",
      " -1.375      -0.75        2.375      -0.125       0.5        -0.75      ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean/tensorflow/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "########### Data ###########\n",
    "user_dic = loadUserFile()\n",
    "item_dic = loadItemFile()\n",
    "userID, item1, item2, labels = loadTrainFile()\n",
    "\n",
    "preference = np.zeros([len(user_dic),10], dtype=int)\n",
    "\n",
    "for idx, label in enumerate(labels):\n",
    "    if(label==0):\n",
    "        preference[userID[idx]-1][item1[idx]-1]+=1\n",
    "#         preference[userID[idx]-1][item2[idx]-1]-=1\n",
    "    else:\n",
    "#         preference[userID[idx]-1][item1[idx]-1]-=1\n",
    "        preference[userID[idx]-1][item2[idx]-1]+=1\n",
    "\n",
    "preference = preprocessing.scale(preference, axis=1, copy=False)\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(len(user_dic)):\n",
    "    for j in range(len(item_dic)):\n",
    "        X_train.append(np.concatenate([user_dic[i].astype(float),item_dic[j].astype(float)]))\n",
    "        y_train.append(preference[i][j])\n",
    "X_train = np.array(X_train)\n",
    "X_train = preprocessing.scale(X_train, axis=0, copy=False)\n",
    "y_train = np.array(y_train).reshape(len(y_train))\n",
    "print(X_train)\n",
    "print(y_train)\n",
    "\n",
    "########### Data ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Model ###########\n",
    "x = tf.placeholder(tf.float32, [None, X_train.shape[1]], name='x')\n",
    "y = tf.placeholder(tf.float32, [None], name='y')\n",
    "\n",
    "logits = dnn(x)\n",
    "loss = tf.reduce_mean(tf.square(logits-y), name='loss')\n",
    "\n",
    "# Training iteration\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=LEARNING_RATE)\n",
    "train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "\n",
    "# # Calculate Accuracy\n",
    "# probabilities = tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "# correct_prediction = tf.equal(y, tf.argmax(probabilities,1,output_type=tf.int32))\n",
    "# accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Start training ##########\n",
      "########## Fold: 1 ##########\n",
      "validate data:  (60, 8)\n",
      "validate label:  (60,)\n",
      "train data:  (540, 8)\n",
      "train label:  (540,)\n",
      "INFO:tensorflow:Restoring parameters from ./saved_model/dnn.ckpt\n",
      "Epoch:  119  Loss:  0.8400482\n",
      "########## Fold: 2 ##########\n",
      "validate data:  (60, 8)\n",
      "validate label:  (60,)\n",
      "train data:  (540, 8)\n",
      "train label:  (540,)\n",
      "INFO:tensorflow:Restoring parameters from ./saved_model/dnn.ckpt\n",
      "Epoch:  109  Loss:  1.0964218\n",
      "########## Fold: 3 ##########\n",
      "validate data:  (60, 8)\n",
      "validate label:  (60,)\n",
      "train data:  (540, 8)\n",
      "train label:  (540,)\n",
      "INFO:tensorflow:Restoring parameters from ./saved_model/dnn.ckpt\n",
      "Epoch:  221  Loss:  0.8552751\n",
      "########## Fold: 4 ##########\n",
      "validate data:  (60, 8)\n",
      "validate label:  (60,)\n",
      "train data:  (540, 8)\n",
      "train label:  (540,)\n",
      "INFO:tensorflow:Restoring parameters from ./saved_model/dnn.ckpt\n",
      "Epoch:  101  Loss:  0.8963422\n",
      "########## Fold: 5 ##########\n",
      "validate data:  (60, 8)\n",
      "validate label:  (60,)\n",
      "train data:  (540, 8)\n",
      "train label:  (540,)\n",
      "INFO:tensorflow:Restoring parameters from ./saved_model/dnn.ckpt\n",
      "Epoch:  125  Loss:  1.0689468\n",
      "########## Fold: 6 ##########\n",
      "validate data:  (60, 8)\n",
      "validate label:  (60,)\n",
      "train data:  (540, 8)\n",
      "train label:  (540,)\n",
      "INFO:tensorflow:Restoring parameters from ./saved_model/dnn.ckpt\n",
      "Epoch:  108  Loss:  1.0060867\n",
      "########## Fold: 7 ##########\n",
      "validate data:  (60, 8)\n",
      "validate label:  (60,)\n",
      "train data:  (540, 8)\n",
      "train label:  (540,)\n",
      "INFO:tensorflow:Restoring parameters from ./saved_model/dnn.ckpt\n",
      "Epoch:  132  Loss:  1.1227124\n",
      "########## Fold: 8 ##########\n",
      "validate data:  (60, 8)\n",
      "validate label:  (60,)\n",
      "train data:  (540, 8)\n",
      "train label:  (540,)\n",
      "INFO:tensorflow:Restoring parameters from ./saved_model/dnn.ckpt\n",
      "Epoch:  122  Loss:  0.7630223\n",
      "########## Fold: 9 ##########\n",
      "validate data:  (60, 8)\n",
      "validate label:  (60,)\n",
      "train data:  (540, 8)\n",
      "train label:  (540,)\n",
      "INFO:tensorflow:Restoring parameters from ./saved_model/dnn.ckpt\n",
      "Epoch:  303  Loss:  1.1733309\n",
      "########## Fold: 10 ##########\n",
      "validate data:  (60, 8)\n",
      "validate label:  (60,)\n",
      "train data:  (540, 8)\n",
      "train label:  (540,)\n",
      "INFO:tensorflow:Restoring parameters from ./saved_model/dnn.ckpt\n",
      "Epoch:  104  Loss:  1.0792198\n",
      "average loss:  0.9901406288146972\n"
     ]
    }
   ],
   "source": [
    "########## Train ##########\n",
    "print(\"########## Start training ##########\")\n",
    "sess = tf.Session()\n",
    "writer = tf.summary.FileWriter(\"./log\", sess.graph)\n",
    "init = tf.global_variables_initializer()\n",
    "# init saver to save model\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# randomize dataset\n",
    "indices = np.random.permutation(X_train.shape[0])\n",
    "\n",
    "# start cross validation\n",
    "avg_loss = 0.0\n",
    "\n",
    "if TAKE_CROSS_VALIDATION == True:\n",
    "    for fold in range(1, CROSS_VALIDATION+1):\n",
    "        print(\"########## Fold:\", fold, \"##########\")\n",
    "        # init weights\n",
    "        sess.run(init)\n",
    "        # split inputs into training set and validation set for each fold\n",
    "        X_train_fold, y_train_fold, X_validate_fold, y_validate_fold = split_folds(indices, X_train, y_train, CROSS_VALIDATION, fold)\n",
    "        print('validate data: ', X_validate_fold.shape)\n",
    "        print('validate label: ', y_validate_fold.shape)\n",
    "        print('train data: ', X_train_fold.shape)\n",
    "        print('train label: ', y_train_fold.shape)\n",
    "\n",
    "        winner_loss, epoch = train(X_train_fold, y_train_fold, X_validate_fold, y_validate_fold\n",
    "                                , train_op, EPOCH_BOUND, EARLY_STOP_CHECK_EPOCH, BATCH_SIZE, testing=False)\n",
    "        avg_loss += winner_loss\n",
    "        \n",
    "        \n",
    "        print(\"Epoch: \", epoch, \" Loss: \", winner_loss)\n",
    "    avg_loss /= CROSS_VALIDATION\n",
    "    \n",
    "    \n",
    "    print(\"average loss: \", avg_loss)\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Start training ##########\n"
     ]
    }
   ],
   "source": [
    "########## Hyperparameter ##########\n",
    "BATCH_SIZE = 5\n",
    "EPOCH = 150\n",
    "LEARNING_RATE = 0.05\n",
    "########## Hyperparameter ##########\n",
    "########## Final Train ##########\n",
    "sess = tf.Session()\n",
    "writer = tf.summary.FileWriter(\"./log\", sess.graph)\n",
    "init = tf.global_variables_initializer()\n",
    "# init saver to save model\n",
    "saver = tf.train.Saver()\n",
    "print(\"########## Start training ##########\")\n",
    "sess.run(init)\n",
    "\n",
    "for epoch in range(EPOCH):\n",
    "\n",
    "        # randomize training set\n",
    "        indices_training = np.random.permutation(X_train.shape[0])\n",
    "        X_train, y_train = X_train[indices_training,:], y_train[indices_training]\n",
    "        \n",
    "        # split training set into multiple mini-batches and start training\n",
    "        total_batches = int(X_train.shape[0] / BATCH_SIZE)\n",
    "        for batch in range(total_batches):\n",
    "            if batch == total_batches - 1:\n",
    "                sess.run(train_op, feed_dict={x: X_train[batch*BATCH_SIZE:], \n",
    "                                               y: y_train[batch*BATCH_SIZE:]})\n",
    "            else:\n",
    "                sess.run(train_op, feed_dict={x: X_train[batch*BATCH_SIZE : (batch+1)*BATCH_SIZE], \n",
    "                                               y: y_train[batch*BATCH_SIZE : (batch+1)*BATCH_SIZE]})\n",
    "writer.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.47659481e-01]\n",
      " [-2.97247842e-02]\n",
      " [-6.79320768e-02]\n",
      " [-7.66169950e-02]\n",
      " [-2.64696851e-02]\n",
      " [ 3.33014876e-02]\n",
      " [-2.88119167e-03]\n",
      " [ 1.12030305e-01]\n",
      " [ 1.12030305e-01]\n",
      " [ 1.33619532e-02]\n",
      " [-4.44168076e-02]\n",
      " [-5.37030399e-04]\n",
      " [-1.38820350e-01]\n",
      " [-4.94357869e-02]\n",
      " [ 1.12030305e-01]\n",
      " [ 1.12030305e-01]\n",
      " [-8.32894668e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-9.37804058e-02]\n",
      " [ 1.12030305e-01]\n",
      " [ 6.49837926e-02]\n",
      " [-5.75906411e-02]\n",
      " [-5.67488447e-02]\n",
      " [ 3.88700441e-02]\n",
      " [ 3.27541828e-02]\n",
      " [ 7.46758729e-02]\n",
      " [ 5.66167720e-02]\n",
      " [-1.18446924e-01]\n",
      " [ 5.69018871e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-6.74689561e-03]\n",
      " [-3.91212925e-02]\n",
      " [ 1.12030305e-01]\n",
      " [ 1.12030305e-01]\n",
      " [-1.61073878e-02]\n",
      " [ 3.09761912e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-5.06874993e-02]\n",
      " [ 1.06181212e-01]\n",
      " [ 1.12030305e-01]\n",
      " [ 1.12030305e-01]\n",
      " [ 1.12030305e-01]\n",
      " [-3.11673954e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-4.83555421e-02]\n",
      " [-1.20097153e-01]\n",
      " [-7.75989667e-02]\n",
      " [ 8.92842337e-02]\n",
      " [ 1.12030305e-01]\n",
      " [ 1.54736489e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-1.63464069e-01]\n",
      " [ 8.39003175e-03]\n",
      " [ 8.19950476e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-1.75812632e-01]\n",
      " [-8.68418068e-03]\n",
      " [-1.06176727e-01]\n",
      " [-1.29467696e-01]\n",
      " [-1.16097532e-01]\n",
      " [-3.73154879e-03]\n",
      " [-6.58353046e-02]\n",
      " [-1.07980736e-01]\n",
      " [-9.46009681e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-5.29598519e-02]\n",
      " [-7.80732930e-03]\n",
      " [-1.05616353e-01]\n",
      " [ 6.20074272e-02]\n",
      " [ 1.01946741e-01]\n",
      " [-5.37030399e-04]\n",
      " [-5.27820811e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-9.60613862e-02]\n",
      " [ 1.12030305e-01]\n",
      " [ 1.12030305e-01]\n",
      " [-1.10262953e-01]\n",
      " [ 1.12030305e-01]\n",
      " [-6.99900091e-03]\n",
      " [ 9.86914262e-02]\n",
      " [-1.05250306e-01]\n",
      " [ 1.04269758e-01]\n",
      " [ 6.00493774e-02]\n",
      " [ 1.12030305e-01]\n",
      " [ 1.12030305e-01]\n",
      " [-9.57029238e-02]\n",
      " [-5.50354943e-02]\n",
      " [-9.97352377e-02]\n",
      " [-6.45700768e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-2.58334652e-02]\n",
      " [ 7.85872340e-02]\n",
      " [-1.65121034e-02]\n",
      " [-3.89434025e-02]\n",
      " [-2.90171877e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-2.73726657e-02]\n",
      " [-8.31491277e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-5.88104352e-02]\n",
      " [ 3.27702537e-02]\n",
      " [ 1.54736489e-02]\n",
      " [-1.82192400e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-1.24160074e-01]\n",
      " [-5.38355932e-02]\n",
      " [-1.23166718e-01]\n",
      " [ 8.22643787e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-2.97247842e-02]\n",
      " [-1.46630287e-01]\n",
      " [-5.77805862e-02]\n",
      " [ 1.37133002e-02]\n",
      " [ 7.46758729e-02]\n",
      " [ 4.02621776e-02]\n",
      " [ 5.36248907e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-8.23075250e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-1.45923421e-02]\n",
      " [-1.17633052e-01]\n",
      " [-6.84465095e-02]\n",
      " [-1.05894081e-01]\n",
      " [-4.86908183e-02]\n",
      " [-3.40806171e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-1.27435237e-01]\n",
      " [ 1.12030305e-01]\n",
      " [-1.11327656e-01]\n",
      " [-5.15723005e-02]\n",
      " [-8.57546553e-02]\n",
      " [ 3.69784310e-02]\n",
      " [ 1.12030305e-01]\n",
      " [ 1.12030305e-01]\n",
      " [-7.36064389e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-4.94226292e-02]\n",
      " [-1.62454471e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-6.14090487e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-3.40806171e-02]\n",
      " [ 1.12030305e-01]\n",
      " [ 1.12030305e-01]\n",
      " [-1.59207359e-02]\n",
      " [-9.36430022e-02]\n",
      " [-1.15845017e-01]\n",
      " [ 1.12030305e-01]\n",
      " [-5.56150451e-02]\n",
      " [-8.66492912e-02]\n",
      " [-5.18009439e-02]\n",
      " [ 5.46712950e-02]\n",
      " [ 1.12030305e-01]\n",
      " [ 1.12030305e-01]\n",
      " [-6.54404387e-02]\n",
      " [-6.77706525e-02]\n",
      " [-1.39561519e-02]\n",
      " [ 1.12030305e-01]\n",
      " [ 1.12030305e-01]\n",
      " [-5.18009439e-02]\n",
      " [-1.31223083e-01]\n",
      " [-3.27618942e-02]\n",
      " [-1.00476779e-01]\n",
      " [-1.05616353e-01]\n",
      " [-8.86908397e-02]\n",
      " [-1.82192400e-02]\n",
      " [ 1.12030305e-01]\n",
      " [ 5.82416691e-02]\n",
      " [ 1.04483165e-01]\n",
      " [-9.78285745e-02]\n",
      " [-6.45700768e-02]\n",
      " [ 1.12030305e-01]\n",
      " [ 6.00493774e-02]\n",
      " [-8.66492912e-02]\n",
      " [-2.24624351e-02]\n",
      " [-7.18797520e-02]\n",
      " [ 1.12030305e-01]\n",
      " [ 1.12030305e-01]\n",
      " [ 1.12030305e-01]\n",
      " [ 1.12030305e-01]\n",
      " [ 1.12030305e-01]\n",
      " [ 1.12030305e-01]\n",
      " [ 1.12030305e-01]\n",
      " [-9.90896747e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-2.99557671e-02]\n",
      " [ 9.49743688e-02]\n",
      " [-2.23736390e-02]\n",
      " [-9.83418524e-03]\n",
      " [ 8.89739543e-02]\n",
      " [ 1.04438953e-01]\n",
      " [ 2.60367319e-02]\n",
      " [-8.73605981e-02]\n",
      " [ 1.12030305e-01]\n",
      " [ 1.12030305e-01]\n",
      " [ 7.44237602e-02]\n",
      " [-6.88019469e-02]\n",
      " [-1.24391615e-02]\n",
      " [-8.25633481e-02]\n",
      " [ 8.89739543e-02]\n",
      " [-1.19658560e-02]\n",
      " [-4.94357869e-02]\n",
      " [ 6.56152517e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-5.30747846e-02]\n",
      " [-8.38427618e-02]\n",
      " [ 1.33619532e-02]\n",
      " [ 1.12030305e-01]\n",
      " [ 7.55862892e-02]\n",
      " [-5.42568043e-02]\n",
      " [-1.18952923e-01]\n",
      " [ 1.12030305e-01]\n",
      " [ 1.12030305e-01]\n",
      " [ 1.54386684e-02]\n",
      " [ 1.12030305e-01]\n",
      " [ 5.36248907e-02]\n",
      " [ 1.12030305e-01]\n",
      " [ 1.12030305e-01]\n",
      " [-6.16663620e-02]\n",
      " [-1.12639077e-01]\n",
      " [ 1.12030305e-01]\n",
      " [-1.61519408e-01]\n",
      " [-1.81503966e-02]\n",
      " [ 8.22643787e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-1.43791080e-01]\n",
      " [-1.20494969e-01]\n",
      " [-2.52961367e-03]\n",
      " [-1.05957933e-01]\n",
      " [ 1.12030305e-01]\n",
      " [-1.13242574e-01]\n",
      " [ 1.12030305e-01]\n",
      " [-2.90171877e-02]\n",
      " [-5.11589721e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-1.41032010e-01]\n",
      " [-1.30121946e-01]\n",
      " [-8.46223310e-02]\n",
      " [ 1.56520084e-02]\n",
      " [-1.22103579e-01]\n",
      " [-1.10262953e-01]\n",
      " [-1.19734325e-01]\n",
      " [-1.01065882e-01]\n",
      " [-1.27094775e-01]\n",
      " [-2.97867730e-02]\n",
      " [-2.17909142e-02]\n",
      " [-6.34826049e-02]\n",
      " [-5.99254742e-02]\n",
      " [-1.00442089e-01]\n",
      " [-1.24217726e-01]\n",
      " [-1.15845017e-01]\n",
      " [ 1.12030305e-01]\n",
      " [-6.63975552e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-6.35820702e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-8.46092626e-02]\n",
      " [-7.18797520e-02]\n",
      " [ 1.12030305e-01]\n",
      " [ 1.13310590e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-2.07565427e-01]\n",
      " [-4.98179570e-02]\n",
      " [ 1.12030305e-01]\n",
      " [ 1.54386684e-02]\n",
      " [-8.16991404e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-1.19658560e-02]\n",
      " [ 1.12030305e-01]\n",
      " [ 9.25956070e-02]\n",
      " [-9.83418524e-03]\n",
      " [ 1.03430152e-02]\n",
      " [ 8.80059302e-02]\n",
      " [ 7.20704421e-02]\n",
      " [-1.43388420e-01]\n",
      " [-2.01845825e-01]\n",
      " [-9.57029238e-02]\n",
      " [ 1.54386684e-02]\n",
      " [ 1.28440484e-02]\n",
      " [-7.93391541e-02]\n",
      " [ 1.09603696e-01]\n",
      " [-1.10262953e-01]\n",
      " [-4.51851562e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-4.20008674e-02]\n",
      " [-3.67194936e-02]\n",
      " [-1.03054054e-01]\n",
      " [-1.06969960e-01]\n",
      " [ 1.75654888e-02]\n",
      " [ 6.93642125e-02]\n",
      " [ 1.12030305e-01]\n",
      " [ 5.93335032e-02]\n",
      " [-1.43260986e-01]\n",
      " [ 2.64633447e-03]\n",
      " [ 1.12030305e-01]\n",
      " [-2.78928131e-03]\n",
      " [-1.55738533e-01]\n",
      " [ 1.12030305e-01]\n",
      " [ 1.12030305e-01]\n",
      " [ 1.12030305e-01]\n",
      " [-4.18046489e-02]\n",
      " [ 2.09613591e-02]\n",
      " [-1.24217726e-01]\n",
      " [ 1.12030305e-01]\n",
      " [ 1.65184587e-03]\n",
      " [ 8.66926834e-02]\n",
      " [ 1.12846226e-01]\n",
      " [ 1.09603696e-01]\n",
      " [-1.00388378e-02]\n",
      " [-7.76171759e-02]\n",
      " [-2.18023583e-02]\n",
      " [ 1.01994991e-01]\n",
      " [-5.54508939e-02]\n",
      " [-6.88454881e-02]\n",
      " [ 6.41125366e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-2.55305544e-02]\n",
      " [-6.60965592e-03]\n",
      " [ 1.64479390e-02]\n",
      " [ 8.26129988e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-3.40806171e-02]\n",
      " [ 1.00449324e-01]\n",
      " [ 7.38368779e-02]\n",
      " [-7.61975273e-02]\n",
      " [-7.18797520e-02]\n",
      " [-1.50112808e-01]\n",
      " [-1.14467956e-01]\n",
      " [ 5.82852960e-03]\n",
      " [ 1.12030305e-01]\n",
      " [-8.23075250e-02]\n",
      " [ 1.12030305e-01]\n",
      " [ 1.10446781e-01]\n",
      " [-6.59363493e-02]\n",
      " [ 2.09347755e-02]\n",
      " [ 1.12030305e-01]\n",
      " [ 1.12030305e-01]\n",
      " [-8.66492912e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-6.14090487e-02]\n",
      " [ 6.56152517e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-2.17760727e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-3.12367901e-02]\n",
      " [-7.18797520e-02]\n",
      " [-7.71506801e-02]\n",
      " [-4.86902222e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-2.17760727e-02]\n",
      " [-7.98513740e-03]\n",
      " [-6.35788366e-02]\n",
      " [-1.08276166e-01]\n",
      " [ 3.88700441e-02]\n",
      " [-1.29852474e-01]\n",
      " [ 1.12846226e-01]\n",
      " [ 1.12030305e-01]\n",
      " [-2.43952051e-02]\n",
      " [-6.45700768e-02]\n",
      " [-6.30260780e-02]\n",
      " [ 9.94571075e-02]\n",
      " [-3.52250859e-02]\n",
      " [ 1.20137483e-02]\n",
      " [-1.99725702e-02]\n",
      " [ 1.95728913e-02]\n",
      " [-1.24217726e-01]\n",
      " [-7.68131241e-02]\n",
      " [-9.97352377e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-5.12583926e-02]\n",
      " [ 1.12030305e-01]\n",
      " [ 1.12030305e-01]\n",
      " [ 1.12030305e-01]\n",
      " [ 7.92592019e-03]\n",
      " [ 1.12030305e-01]\n",
      " [-7.80732930e-03]\n",
      " [-6.98177442e-02]\n",
      " [ 1.29990876e-02]\n",
      " [ 1.23765916e-02]\n",
      " [ 2.12671384e-02]\n",
      " [-9.78146270e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-1.36360526e-04]\n",
      " [ 1.12030305e-01]\n",
      " [ 1.12030305e-01]\n",
      " [ 1.12030305e-01]\n",
      " [-6.88019469e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-3.75582948e-02]\n",
      " [-1.24217726e-01]\n",
      " [-5.88104352e-02]\n",
      " [-2.03774273e-01]\n",
      " [-3.57963666e-02]\n",
      " [-6.07343689e-02]\n",
      " [-4.86902222e-02]\n",
      " [ 7.64159411e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-3.75582948e-02]\n",
      " [-1.01133801e-01]\n",
      " [-7.46343955e-02]\n",
      " [-1.11327656e-01]\n",
      " [ 1.66800678e-01]\n",
      " [ 6.98994398e-02]\n",
      " [ 1.12030305e-01]\n",
      " [ 6.08013645e-02]\n",
      " [-7.75989667e-02]\n",
      " [-1.25232220e-01]\n",
      " [ 4.06109169e-02]\n",
      " [ 1.07762434e-01]\n",
      " [ 1.12030305e-01]\n",
      " [-1.08276166e-01]\n",
      " [-9.19378027e-02]\n",
      " [-1.40558839e-01]\n",
      " [-4.95026931e-02]\n",
      " [ 1.07637428e-01]\n",
      " [ 1.12030305e-01]\n",
      " [-7.84138814e-02]\n",
      " [-5.74907884e-02]\n",
      " [-9.17621776e-02]\n",
      " [-8.66492912e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-1.61792710e-02]\n",
      " [ 9.97191519e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-5.79583570e-02]\n",
      " [-7.59074017e-02]\n",
      " [ 8.50004107e-02]\n",
      " [-7.93391541e-02]\n",
      " [ 1.54386684e-02]\n",
      " [ 6.60427362e-02]\n",
      " [-3.14101651e-02]\n",
      " [-6.22264966e-02]\n",
      " [-1.07224725e-01]\n",
      " [-1.31256804e-02]\n",
      " [-5.65432012e-04]\n",
      " [ 7.05697164e-02]\n",
      " [-4.88907620e-02]\n",
      " [-1.84244096e-01]\n",
      " [ 1.12030305e-01]\n",
      " [-1.15845017e-01]\n",
      " [ 1.12030305e-01]\n",
      " [-9.57509354e-02]\n",
      " [-2.44261324e-03]\n",
      " [-7.25171193e-02]\n",
      " [-9.83418524e-03]\n",
      " [-6.45700768e-02]\n",
      " [-7.76171759e-02]\n",
      " [ 9.37682688e-02]\n",
      " [-5.35049066e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-1.24217726e-01]\n",
      " [ 6.61949217e-02]\n",
      " [-7.58769140e-02]\n",
      " [ 3.60965729e-03]\n",
      " [-3.40806171e-02]\n",
      " [-1.23497345e-01]\n",
      " [-4.83555421e-02]\n",
      " [-2.97247842e-02]\n",
      " [ 8.90467316e-02]\n",
      " [-4.65854481e-02]\n",
      " [ 1.12030305e-01]\n",
      " [ 1.12030305e-01]\n",
      " [ 1.12030305e-01]\n",
      " [ 8.19950476e-02]\n",
      " [-8.30649510e-02]\n",
      " [-6.45700768e-02]\n",
      " [-2.38030031e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-2.73228511e-02]\n",
      " [-5.65432012e-04]\n",
      " [-8.46223310e-02]\n",
      " [-7.62764737e-02]\n",
      " [-1.29467696e-01]\n",
      " [-1.57643050e-01]\n",
      " [-1.24382101e-01]\n",
      " [-8.04942623e-02]\n",
      " [ 1.12030305e-01]\n",
      " [ 7.05697164e-02]\n",
      " [-8.14126655e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-1.62454471e-02]\n",
      " [-7.76171759e-02]\n",
      " [-4.38894257e-02]\n",
      " [ 1.12030305e-01]\n",
      " [ 1.12030305e-01]\n",
      " [-2.97247842e-02]\n",
      " [ 9.35742632e-02]\n",
      " [-6.33123890e-02]\n",
      " [-1.15845017e-01]\n",
      " [ 2.58124620e-03]\n",
      " [-6.39126971e-02]\n",
      " [-1.51100487e-01]\n",
      " [-9.54202190e-02]\n",
      " [ 1.12030305e-01]\n",
      " [ 3.02643478e-02]\n",
      " [ 1.12030305e-01]\n",
      " [ 1.65184587e-03]\n",
      " [-7.76171759e-02]\n",
      " [-1.24391615e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-1.40086442e-01]\n",
      " [-1.62910998e-01]\n",
      " [ 3.29248831e-02]\n",
      " [ 8.67040306e-02]\n",
      " [-3.67233381e-02]\n",
      " [ 1.07109956e-01]\n",
      " [ 1.39299557e-02]\n",
      " [-6.41352460e-02]\n",
      " [-1.10262953e-01]\n",
      " [-7.90381506e-02]\n",
      " [ 1.12030305e-01]\n",
      " [ 6.64040595e-02]\n",
      " [-9.83418524e-03]\n",
      " [-4.45196256e-02]\n",
      " [ 1.04037404e-01]\n",
      " [ 1.54386684e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-1.13242574e-01]\n",
      " [ 1.12030305e-01]\n",
      " [-1.10262953e-01]\n",
      " [-6.59363493e-02]\n",
      " [-1.05740495e-01]\n",
      " [-6.97493032e-02]\n",
      " [-3.75984386e-02]\n",
      " [-2.38030031e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-1.15609989e-02]\n",
      " [-6.16663620e-02]\n",
      " [-2.00380012e-02]\n",
      " [ 1.12030305e-01]\n",
      " [ 8.66926834e-02]\n",
      " [-9.70124528e-02]\n",
      " [ 1.04560293e-01]\n",
      " [-2.17909142e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-5.35105988e-02]\n",
      " [-4.65854481e-02]\n",
      " [-3.16570029e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-9.96469930e-02]\n",
      " [-4.83555421e-02]\n",
      " [ 5.17906845e-02]\n",
      " [ 3.88700441e-02]\n",
      " [-5.97910360e-02]\n",
      " [-1.33762181e-01]\n",
      " [ 1.10730007e-02]\n",
      " [ 1.88628212e-02]\n",
      " [ 1.20137483e-02]\n",
      " [-9.83418524e-03]\n",
      " [-1.39643878e-01]\n",
      " [ 1.94368511e-02]\n",
      " [ 2.09347755e-02]\n",
      " [-9.37804058e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-2.99557671e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-4.83555421e-02]\n",
      " [-7.52444789e-02]\n",
      " [-2.67864764e-03]\n",
      " [ 5.82416691e-02]\n",
      " [-1.08182319e-01]\n",
      " [ 1.12030305e-01]\n",
      " [-7.25171193e-02]\n",
      " [-8.25633481e-02]\n",
      " [-1.02773733e-01]\n",
      " [ 1.12030305e-01]\n",
      " [ 1.12030305e-01]\n",
      " [-4.83555421e-02]\n",
      " [ 1.12030305e-01]\n",
      " [ 1.12030305e-01]\n",
      " [-3.92358080e-02]\n",
      " [-1.05740495e-01]\n",
      " [-4.45196256e-02]\n",
      " [ 3.88700441e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-2.00033039e-01]\n",
      " [-6.07343689e-02]\n",
      " [-7.59074017e-02]\n",
      " [ 7.84142613e-02]\n",
      " [ 3.96900773e-02]\n",
      " [-1.67103112e-01]\n",
      " [ 1.12030305e-01]\n",
      " [ 2.68097892e-02]\n",
      " [ 1.13310590e-02]\n",
      " [-1.29792780e-01]\n",
      " [-8.38427618e-02]\n",
      " [-1.24160074e-01]\n",
      " [-5.09117916e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-2.62524262e-02]\n",
      " [-7.12035671e-02]\n",
      " [ 2.90807709e-02]\n",
      " [-8.42201039e-02]\n",
      " [-1.14045449e-01]\n",
      " [ 3.42380852e-02]\n",
      " [ 1.12030305e-01]\n",
      " [-2.52961367e-03]\n",
      " [ 1.12030305e-01]\n",
      " [ 1.12030305e-01]\n",
      " [-5.16486391e-02]]\n",
      "0.500733137829912\n"
     ]
    }
   ],
   "source": [
    "hit = 0\n",
    "user_preference = sess.run(logits, feed_dict={x:X_train})\n",
    "print(user_preference)\n",
    "X_train_item1 = np.concatenate([user_dic[userID-1].astype(float), item_dic[item1-1].astype(float)], axis=1)\n",
    "X_train_item2 = np.concatenate([user_dic[userID-1].astype(float), item_dic[item2-1].astype(float)], axis=1)\n",
    "user_preference_item1 = sess.run(logits, feed_dict={x:X_train_item1})\n",
    "user_preference_item2 = sess.run(logits, feed_dict={x:X_train_item2})\n",
    "\n",
    "for idx in range(userID.shape[0]):\n",
    "    entry = str(int(userID[idx]))+'-'+str(int(item1[idx]))+'-'+str(int(item2[idx]))\n",
    "    if(labels[idx]==0 and user_preference_item1[idx]>=user_preference_item2[idx]):\n",
    "        hit+=1\n",
    "    elif(labels[idx]==1 and user_preference_item1[idx]<user_preference_item2[idx]):\n",
    "        hit+=1\n",
    "print(hit/userID.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Test ##########\n",
    "print(\"########## Start Test ##########\")\n",
    "\n",
    "userID, item1, item2 = loadTestFile()\n",
    "\n",
    "X_test_item1 = np.concatenate([user_dic[userID-1].astype(float), item_dic[item1-1]], axis=1)\n",
    "X_test_item2 = np.concatenate([user_dic[userID-1].astype(float), item_dic[item2-1]], axis=1)\n",
    "user_preference_item1 = sess.run(logits, feed_dict={x:X_test_item1})\n",
    "user_preference_item2 = sess.run(logits, feed_dict={x:X_test_item2})\n",
    "\n",
    "test_output=[['User-Item1-Item2','Preference']]\n",
    "for idx in range(userID.shape[0]):\n",
    "    entry = str(int(userID[idx]))+'-'+str(int(item1[idx]))+'-'+str(int(item2[idx]))\n",
    "    if(user_preference_item1[idx]>=user_preference_item2[idx]):\n",
    "        value=0\n",
    "    else:\n",
    "        value=1\n",
    "    test_output.append([entry,value])\n",
    "print(test_output)\n",
    "np.savetxt(\"output.csv\", np.array(test_output, dtype=np.str), fmt='%s,%s', delimiter=\",\")\n",
    "# print(X_test.shape)\n",
    "# print(X_test.astype(float))\n",
    "# for idx, label in enumerate(labels):\n",
    "# #     print(user_preference[userID[idx]*item1[idx]-1])\n",
    "# #     print(user_preference[userID[idx]*item2[idx]-1])\n",
    "#     if(label==0 and (user_preference[userID[idx]*item1[idx]-1]>=user_preference[userID[idx]*item2[idx]-1])):\n",
    "#         hit+=1\n",
    "#     elif(label==1 and (user_preference[userID[idx]*item1[idx]-1]<=user_preference[userID[idx]*item2[idx]-1])):\n",
    "#         hit+=1\n",
    "        \n",
    "# test_output=[['User-Item1-Item2','Preference']]\n",
    "# for idx in range(pridict_output.shape[0]):\n",
    "#     entry = str(int(userID[idx]))+'-'+str(int(item1[idx]))+'-'+str(int(item2[idx]))\n",
    "#     value = pridict_output[idx]\n",
    "#     test_output.append([entry,value])\n",
    "\n",
    "# print(test_output)\n",
    "# np.savetxt(\"output.csv\", np.array(test_output, dtype=np.str), fmt='%s,%s', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-virtualenv-tensorflow",
   "language": "python",
   "name": "my-virtualenv-tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
