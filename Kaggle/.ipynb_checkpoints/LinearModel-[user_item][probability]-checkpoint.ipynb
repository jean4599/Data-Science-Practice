{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model           \n",
    "from sklearn.linear_model  import LinearRegression\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pandas import DataFrame\n",
    "\n",
    "def loadTrainFile():\n",
    "    tmp = np.loadtxt(\"train.csv\", dtype=np.str, delimiter=\",\")\n",
    "    userID = tmp[1:,0].astype(int)\n",
    "    item1 = tmp[1:,1].astype(int)\n",
    "    item2 = tmp[1:,2].astype(int)\n",
    "    labels = tmp[1:,3].astype(int)\n",
    "    return userID, item1, item2, labels\n",
    "def loadTestFile():\n",
    "    tmp = np.loadtxt(\"test.csv\", dtype=np.str, delimiter=\",\")\n",
    "    userID = tmp[1:,0].astype(int)\n",
    "    item1 = tmp[1:,1].astype(int)\n",
    "    item2 = tmp[1:,2].astype(int)\n",
    "    return userID, item1, item2\n",
    "def loadUserFile():\n",
    "    tmp = np.loadtxt(\"users.csv\", dtype=str, delimiter=\",\")\n",
    "    return tmp[1:,1:]\n",
    "\n",
    "def loadItemFile():\n",
    "    tmp = np.loadtxt(\"items.csv\", dtype=np.str, delimiter=\",\")\n",
    "    return tmp[1:,1:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.         -1.13592367  1.13592367  0.85194275  0.85194275 -0.56796183\n",
      " -1.98786642 -0.56796183  0.28398092  1.13592367  0.65938047 -0.65938047\n",
      "  1.31876095 -0.32969024 -0.98907071 -0.65938047  1.64845118 -0.65938047\n",
      "  0.98907071 -1.31876095 -0.56796183  1.13592367 -0.56796183 -0.28398092\n",
      " -1.41990459  0.56796183  1.98786642  0.56796183 -0.28398092 -1.13592367\n",
      "  0.58722022 -1.17444044  1.76166066  0.88083033  0.29361011 -1.17444044\n",
      " -0.88083033 -1.17444044  0.88083033  0.          0.          0.\n",
      "  0.         -1.18585412  1.18585412  0.79056942 -1.18585412  1.58113883\n",
      "  0.39528471 -1.58113883  0.62017367 -1.24034735  1.24034735  0.31008684\n",
      "  0.93026051  0.         -2.17060786 -0.62017367  0.31008684  0.62017367\n",
      "  0.         -1.17444044  1.76166066  0.88083033  0.88083033 -1.17444044\n",
      " -0.29361011 -1.17444044  0.88083033 -0.58722022  0.60858062 -1.21716124\n",
      " -0.60858062 -0.30429031  1.52145155  0.60858062 -1.52145155  1.21716124\n",
      " -0.91287093  0.60858062  0.          0.31311215  0.93933644  0.62622429\n",
      "  0.31311215 -0.93933644 -0.93933644 -2.19178502  0.62622429  1.25244858\n",
      "  0.          1.79284291 -1.79284291 -0.89642146 -0.29880715  0.5976143\n",
      "  0.29880715  1.19522861 -0.89642146  0.          0.64549722  0.64549722\n",
      " -1.29099445 -0.96824584 -0.96824584  1.29099445  0.96824584  1.29099445\n",
      " -0.96824584 -0.64549722  0.          0.95346259  0.         -1.43019388\n",
      " -0.47673129 -0.95346259  2.38365647  0.         -0.47673129  0.\n",
      " -0.63245553 -0.63245553  1.8973666   0.9486833   0.31622777 -1.26491106\n",
      "  0.31622777 -1.26491106  0.9486833  -0.63245553  0.          0.56343617\n",
      "  1.12687234  0.28171808 -0.84515425 -1.69030851  1.40859042 -1.40859042\n",
      "  0.84515425 -0.28171808  1.19522861 -1.79284291  1.19522861  0.29880715\n",
      "  0.89642146 -0.5976143  -1.49403576  0.         -0.29880715  0.5976143\n",
      "  1.          0.          1.          0.5         1.5         0.\n",
      " -1.5         0.         -1.5        -1.          0.         -1.17444044\n",
      "  1.76166066  0.88083033  0.88083033 -1.17444044 -0.88083033 -1.17444044\n",
      "  0.29361011  0.58722022 -0.60858062 -0.60858062  1.82574186  0.91287093\n",
      "  0.91287093 -1.21716124 -0.30429031 -1.21716124  0.91287093 -0.60858062\n",
      "  0.         -1.62697843  1.62697843  0.81348922  0.81348922 -1.08465229\n",
      "  0.27116307 -1.08465229  0.81348922 -0.54232614  1.49071198 -1.49071198\n",
      "  0.74535599  0.372678    1.11803399  0.         -1.11803399  0.74535599\n",
      " -1.11803399 -0.74535599  0.          1.24034735 -1.24034735 -0.93026051\n",
      " -0.93026051  1.24034735  0.93026051  1.24034735 -0.93026051 -0.62017367\n",
      " -0.67419986 -0.67419986  2.02259959  1.01129979  0.33709993 -0.67419986\n",
      " -1.01129979 -1.34839972  0.33709993  0.67419986  1.17444044 -0.58722022\n",
      " -0.58722022 -0.29361011  0.88083033  0.58722022 -2.05527077  1.17444044\n",
      " -0.88083033  0.58722022  0.         -1.17444044  1.76166066  0.88083033\n",
      "  0.88083033 -1.17444044 -0.29361011 -1.17444044  0.88083033 -0.58722022\n",
      "  0.64549722 -1.29099445  1.93649167  0.96824584  0.32274861 -1.29099445\n",
      " -0.96824584 -0.64549722  0.32274861  0.          0.55048188 -1.65144565\n",
      "  1.65144565  0.82572282  0.27524094 -0.55048188  0.27524094 -1.10096377\n",
      "  0.82572282 -1.10096377  1.19522861 -1.19522861 -1.19522861 -0.29880715\n",
      "  0.29880715  1.19522861 -1.49403576  1.19522861 -0.29880715  0.5976143\n",
      " -0.57735027  0.57735027  0.57735027  0.28867513 -1.44337567 -0.57735027\n",
      "  2.02072594 -1.15470054  0.8660254  -0.57735027 -1.38013112  1.38013112\n",
      "  0.69006556  1.03509834 -0.34503278 -0.69006556 -0.34503278 -1.38013112\n",
      " -0.34503278  1.38013112  0.48795004 -0.48795004 -0.97590007 -0.97590007\n",
      "  1.95180015  0.48795004  0.48795004 -0.48795004  0.97590007 -1.46385011\n",
      "  1.34839972 -2.02259959  1.34839972 -0.33709993  0.33709993 -0.67419986\n",
      " -1.01129979  0.          0.33709993  0.67419986 -0.33709993  0.\n",
      "  1.68549966  1.01129979  1.01129979 -1.34839972 -0.67419986 -1.34839972\n",
      " -0.67419986  0.67419986 -0.55048188  0.55048188  1.10096377  0.27524094\n",
      " -1.37620471  0.          1.92668659 -1.10096377  0.27524094 -1.10096377\n",
      "  0.33333333 -0.33333333  2.          0.33333333  0.66666667 -1.33333333\n",
      "  0.33333333 -1.66666667  0.33333333 -0.66666667  1.15044748 -1.91741247\n",
      "  1.15044748  0.38348249  1.15044748  0.38348249 -0.38348249  0.\n",
      " -0.76696499 -1.15044748  0.         -1.15470054  1.73205081  0.8660254\n",
      "  0.8660254  -1.15470054 -0.8660254  -1.15470054  0.8660254   0.\n",
      "  0.          1.08465229 -1.62697843 -0.81348922 -0.81348922  0.54232614\n",
      "  1.89814151  0.54232614 -0.81348922  0.          0.58722022 -1.17444044\n",
      "  1.76166066  0.88083033  0.29361011 -1.17444044 -0.88083033 -1.17444044\n",
      "  0.88083033  0.          0.55901699 -1.67705098  1.67705098  0.83852549\n",
      "  0.2795085  -1.11803399 -0.2795085  -1.11803399  0.83852549  0.\n",
      "  1.17444044 -1.76166066  1.17444044  0.29361011  0.88083033 -1.17444044\n",
      " -0.88083033 -0.58722022  0.88083033  0.          0.          0.\n",
      "  1.97814142  0.98907071  0.32969024 -0.65938047 -1.64845118 -0.65938047\n",
      " -0.98907071  0.65938047 -0.60858062  0.60858062  1.82574186  0.91287093\n",
      " -0.91287093 -1.21716124  0.91287093 -1.21716124  0.30429031 -0.60858062\n",
      "  1.17444044 -1.76166066  1.17444044  0.29361011  0.88083033 -0.58722022\n",
      " -1.46805055 -0.58722022  0.29361011  0.58722022  0.60858062  0.60858062\n",
      " -1.82574186 -0.91287093 -0.91287093  1.21716124  0.91287093  1.21716124\n",
      " -0.30429031 -0.60858062 -0.72547625  0.72547625 -0.36273813  0.72547625\n",
      " -1.4509525  -0.72547625  1.08821438  0.          1.81369063 -1.08821438\n",
      "  1.26491106 -1.8973666   0.         -0.31622777  0.9486833   0.\n",
      " -1.58113883  0.63245553  0.9486833   0.          1.15470054 -1.15470054\n",
      "  0.57735027 -0.28867513  0.8660254  -0.57735027 -2.02072594  1.15470054\n",
      " -0.28867513  0.57735027  0.28171808 -0.84515425  1.97202659  0.\n",
      "  0.         -1.40859042  0.28171808 -1.40859042  1.12687234  0.\n",
      "  0.64549722  0.64549722 -1.93649167 -0.96824584 -0.96824584  0.64549722\n",
      "  0.96824584  1.29099445  0.32274861 -0.64549722  0.61429512  0.92144268\n",
      "  0.61429512  1.22859023  0.30714756 -1.53573779  0.30714756 -1.84288535\n",
      "  0.30714756 -0.92144268  1.17444044 -1.76166066  1.76166066 -0.29361011\n",
      "  0.29361011 -0.58722022 -0.29361011  0.58722022  0.29361011 -1.17444044\n",
      "  1.31876095 -1.31876095  1.31876095  0.32969024  0.98907071  0.\n",
      " -1.64845118  0.         -0.98907071  0.          0.56796183 -1.7038855\n",
      "  1.7038855   0.85194275  0.28398092 -1.13592367 -0.85194275 -0.56796183\n",
      "  0.85194275  0.          0.         -1.34839972  0.67419986  1.01129979\n",
      "  1.01129979 -0.67419986 -1.68549966 -0.67419986  0.33709993  1.34839972\n",
      "  0.         -1.17444044  1.76166066  0.88083033  0.88083033 -1.17444044\n",
      " -0.29361011 -1.17444044  0.88083033 -0.58722022 -0.5976143  -1.19522861\n",
      "  1.79284291  0.89642146  0.89642146 -0.5976143  -0.89642146 -1.19522861\n",
      "  0.89642146  0.         -0.2795085   0.83852549  0.         -0.55901699\n",
      " -1.95655948  0.55901699  1.67705098  0.83852549  0.         -1.11803399\n",
      "  0.4472136   0.          0.          0.4472136   2.23606798 -0.4472136\n",
      " -1.78885438  0.4472136  -0.4472136  -0.89442719  0.         -0.33333333\n",
      " -1.         -1.33333333  0.33333333  1.          0.          2.33333333\n",
      " -0.66666667 -0.33333333 -0.5976143   0.29880715  0.89642146  0.5976143\n",
      " -1.49403576 -1.19522861  1.79284291 -0.5976143   0.89642146 -0.5976143 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean/tensorflow/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "########### Data ###########\n",
    "user_dic = loadUserFile()\n",
    "item_dic = loadItemFile()\n",
    "userID, item1, item2, labels = loadTrainFile()\n",
    "\n",
    "preference = np.zeros([len(user_dic),10], dtype=int)\n",
    "\n",
    "for idx, label in enumerate(labels):\n",
    "    if(label==0):\n",
    "        preference[userID[idx]-1][item1[idx]-1]+=1\n",
    "        preference[userID[idx]-1][item2[idx]-1]-=1\n",
    "    else:\n",
    "        preference[userID[idx]-1][item1[idx]-1]-=1\n",
    "        preference[userID[idx]-1][item2[idx]-1]+=1\n",
    "\n",
    "preference = preprocessing.scale(preference, axis=1, copy=False)\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(len(user_dic)):\n",
    "    for j in range(len(item_dic)):\n",
    "        X_train.append(np.concatenate([user_dic[i].astype(float),item_dic[j].astype(float)]))\n",
    "        y_train.append(preference[i][j])\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train).reshape(len(y_train))\n",
    "print(y_train)\n",
    "\n",
    "########### Data ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.64549722  1.76166066  0.57735027  1.15044748 -0.2795085   0.72547625\n",
      "  0.55048188  0.4472136   0.32969024 -1.17444044  0.64549722  0.91287093\n",
      "  0.29361011  0.28171808  0.88083033 -0.58722022  0.         -0.4472136\n",
      "  0.85194275 -1.33333333 -1.46805055 -1.24034735  1.31876095  1.34839972\n",
      " -0.67419986  0.62017367 -1.17444044 -0.91287093 -0.29361011  1.19522861\n",
      "  0.88083033  0.4472136  -1.95655948  0.93026051 -0.60858062 -1.01129979\n",
      "  0.91287093 -0.65938047 -0.96824584  0.79056942 -1.98786642  0.29880715\n",
      "  0.30429031 -1.19522861  0.60858062  0.65938047 -0.30429031 -0.58722022\n",
      " -0.4472136  -0.89642146  0.8660254  -1.11803399  0.66666667 -0.60858062\n",
      " -1.19522861  0.89642146 -0.2795085   1.21716124  1.01129979 -0.84515425\n",
      " -0.47673129 -1.62697843  0.          0.          1.17444044  1.17444044\n",
      " -1.7038855  -1.17444044  0.29880715  0.28171808  0.58722022  0.88083033\n",
      "  0.88083033 -0.33709993  1.12687234  0.89642146  0.57735027  1.93649167\n",
      " -1.17444044  0.          1.82574186 -0.29361011  0.29880715 -0.64549722\n",
      "  0.56796183  0.89642146  1.25244858  1.67705098 -0.98907071  0.\n",
      " -1.18585412 -0.29880715  0.9486833   0.          1.29099445  0.55901699\n",
      "  1.76166066  0.         -1.11803399 -1.21716124 -1.17444044 -1.29099445\n",
      "  0.29361011 -0.96824584  0.         -1.17444044  0.33709993  0.38348249\n",
      " -0.65938047  0.54232614 -0.67419986  0.8660254   1.98786642  1.01129979\n",
      " -1.17444044  0.         -1.15470054  0.          1.22859023 -0.84515425\n",
      "  0.88083033 -0.33333333  0.          1.65144565  0.83852549  0.30714756\n",
      "  0.372678    1.08465229 -0.29880715  1.19522861 -1.19522861 -0.60858062\n",
      "  0.97590007 -1.43019388  0.98907071 -1.52145155  0.58722022 -0.5976143\n",
      " -1.66666667 -1.76166066  0.81348922  1.79284291  2.          1.15044748\n",
      " -1.         -0.5976143   0.33333333  0.33333333  0.65938047 -0.65938047\n",
      " -1.21716124  0.         -1.19522861  0.88083033  0.          0.96824584\n",
      " -1.17444044  1.17444044  0.31622777  0.61429512  0.         -1.17444044\n",
      "  1.97814142 -0.67419986 -2.02259959  0.5976143   0.29361011 -1.64845118\n",
      " -1.40859042  0.33333333 -0.56796183  1.15470054 -0.60858062  1.79284291\n",
      "  1.76166066  0.33333333 -1.08821438  0.58722022  0.         -0.66666667\n",
      " -1.08465229  0.64549722  1.19522861 -0.56796183  0.5         0.93026051\n",
      "  0.58722022  0.33709993 -1.58113883 -0.29361011  0.64549722  0.69006556\n",
      " -0.67419986  0.          0.57735027 -1.15470054 -2.17060786  0.\n",
      "  0.9486833  -0.57735027 -0.97590007 -0.93026051 -0.33709993 -0.69006556\n",
      " -1.17444044  0.88083033  0.          0.67419986  0.          0.88083033\n",
      "  0.31622777  1.5         0.62017367  0.          0.55901699  0.8660254\n",
      " -1.5        -1.24034735 -0.28867513 -0.8660254   0.67419986  1.52145155\n",
      "  0.85194275 -0.28867513 -0.91287093  0.          0.64549722 -0.56796183\n",
      " -1.79284291  0.         -1.69030851 -1.10096377  0.         -0.56796183\n",
      "  2.02072594 -0.34503278  0.          0.4472136   1.38013112  1.17444044\n",
      " -0.29361011 -0.63245553  0.31311215  0.72547625  0.33709993  1.\n",
      " -0.89442719  0.         -0.66666667  0.88083033 -0.72547625  1.29099445\n",
      " -0.58722022  0.         -1.49071198  2.38365647  1.17444044 -0.64549722\n",
      "  0.88083033  0.96824584 -2.02072594  0.88083033  1.29099445 -1.68549966\n",
      "  0.          0.          0.89642146 -0.89642146  0.          1.12687234\n",
      "  1.82574186  1.21716124 -1.11803399 -0.5976143   1.          0.\n",
      " -0.58722022  0.98907071  1.10096377  0.82572282 -0.88083033 -0.58722022\n",
      "  1.13592367  1.15044748 -0.58722022  0.         -1.49403576  1.38013112\n",
      " -1.29099445  0.88083033  0.30714756 -0.47673129 -0.5976143  -1.40859042\n",
      " -1.58113883 -0.30429031  0.67419986  0.29361011  0.         -1.21716124\n",
      " -0.98907071  0.29361011 -1.21716124  1.40859042  0.58722022  0.27524094\n",
      " -0.91287093 -1.17444044  1.01129979  0.98907071 -0.55048188  1.76166066\n",
      "  0.28171808  0.88083033  0.62622429  0.48795004  1.18585412  0.8660254\n",
      " -1.91741247 -1.17444044 -0.74535599  0.         -1.78885438  0.89642146\n",
      "  1.17444044 -0.81348922  0.33709993  1.34839972 -1.34839972 -0.48795004\n",
      " -0.30429031  0.48795004 -1.17444044 -1.76166066 -1.13592367  0.\n",
      " -1.76166066  0.29361011  0.67419986  0.         -1.34839972  0.56796183\n",
      "  0.92144268 -0.33333333 -1.5         0.61429512 -0.58722022  0.84515425\n",
      "  2.02259959 -0.96824584  0.         -0.29361011 -0.56796183 -0.67419986\n",
      "  1.01129979 -0.54232614  0.33709993  0.89642146 -0.93026051  0.88083033\n",
      " -1.10096377 -1.17444044 -1.41990459 -1.67705098 -1.01129979  1.34839972\n",
      " -0.31622777 -0.29361011 -0.63245553 -1.15044748  0.95346259 -0.88083033\n",
      "  1.19522861  1.24034735  0.         -1.44337567 -1.64845118  0.60858062\n",
      "  1.15470054  0.57735027 -1.10096377 -0.32969024 -1.38013112  1.92668659\n",
      " -0.63245553 -1.65144565 -0.88083033  0.91287093 -1.31876095 -1.17444044\n",
      "  0.62622429 -0.72547625  0.          0.29361011 -0.57735027 -1.84288535\n",
      "  0.56796183  0.          0.5976143   0.91287093  1.          1.64845118\n",
      "  0.30714756 -0.33333333 -0.64549722  1.7038855  -1.15470054  0.32969024\n",
      " -0.28171808 -1.17444044 -1.8973666   1.19522861  1.73205081 -0.57735027\n",
      " -1.34839972  0.27524094  1.76166066  0.32274861  1.26491106 -0.60858062\n",
      " -0.96824584 -0.67419986 -1.31876095  0.27524094  0.48795004  0.\n",
      "  0.5976143  -0.81348922 -2.05527077 -0.29880715  0.85194275 -1.17444044\n",
      " -1.26491106 -1.38013112 -0.34503278  1.21716124 -0.55901699 -1.4509525\n",
      "  0.81348922 -1.17444044 -0.5976143   2.33333333 -0.57735027  1.95180015\n",
      "  1.67705098  1.62697843  1.76166066  0.          0.          0.82572282\n",
      " -0.65938047  0.         -1.18585412 -0.93933644 -0.88083033  0.31008684\n",
      "  0.          0.60858062 -0.62017367 -0.29880715  0.9486833  -0.89642146\n",
      " -1.17444044  0.         -0.28398092  0.85194275  0.58722022  1.31876095\n",
      "  0.83852549  1.24034735 -0.81348922 -1.11803399 -0.97590007  0.27524094\n",
      "  0.74535599  0.5976143  -1.          0.58722022 -0.67419986  0.88083033\n",
      "  1.17444044  0.29880715  0.          0.56343617  1.58113883 -1.37620471\n",
      " -0.93026051  0.31311215  0.88083033  1.79284291  0.93933644  0.60858062\n",
      "  0.         -0.48795004 -0.62017367  0.55048188 -1.10096377  2.23606798\n",
      " -0.36273813  0.          0.83852549 -1.33333333  0.28867513  0.32274861\n",
      " -0.5976143   0.31008684  0.83852549  0.9486833  -0.28398092  0.81348922\n",
      "  0.          1.31876095  0.          0.32274861  0.88083033  0.88083033\n",
      "  1.19522861 -0.34503278  0.29361011  0.         -1.21716124  0.\n",
      "  1.81369063  0.60858062 -0.95346259 -0.60858062 -0.67419986  0.91287093\n",
      " -2.19178502 -1.19522861  0.96824584  1.01129979 -0.88083033  1.97202659\n",
      "  0.60858062 -1.15470054  1.13592367  0.          0.74535599  0.        ]\n",
      "[[3.  3.  2.  ... 2.  5.5 1. ]\n",
      " [3.  2.  1.  ... 1.  4.5 2. ]\n",
      " [3.  1.  2.  ... 2.  5.5 1. ]\n",
      " ...\n",
      " [3.  2.  1.  ... 2.  4.5 2. ]\n",
      " [3.  3.  2.  ... 1.  4.5 2. ]\n",
      " [3.  4.  2.  ... 2.  4.5 2. ]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'LinearRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-878aec993417>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0msvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_fold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train_fold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#model評估\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LinearRegression' is not defined"
     ]
    }
   ],
   "source": [
    "########### Model ###########\n",
    "\n",
    "# # Split data into training data and testing data\n",
    "X_train_fold, X_test_fold, y_train_fold, y_test_fold = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
    "print(y_train_fold)\n",
    "print(X_train_fold)\n",
    "svm = LinearRegression()\n",
    "svm.fit(X_train_fold,y_train_fold)\n",
    "#model評估\n",
    "y_pred = svm.predict(X_test)\n",
    "print(\"Misclassified sample: %d\" % (Y_test != y_pred).sum())\n",
    "print(\"Accuracy: %.2f\" % accuracy_score(Y_test,y_pred))\n",
    "precision,recall,fscore,support = precision_recall_fscore_support(Y_test, y_pred, average='micro')\n",
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)\n",
    "print(\"fscore: \", fscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Test ##########\n",
    "print(\"########## Start Test ##########\")\n",
    "\n",
    "userID, item1, item2 = loadTestFile()\n",
    "\n",
    "X_test_item1 = np.concatenate([user_dic[userID-1].astype(float), item_dic[item1-1]], axis=1)\n",
    "X_test_item2 = np.concatenate([user_dic[userID-1].astype(float), item_dic[item2-1]], axis=1)\n",
    "user_preference_item1 = sess.run(logits, feed_dict={x:X_test_item1})\n",
    "user_preference_item2 = sess.run(logits, feed_dict={x:X_test_item2})\n",
    "\n",
    "test_output=[['User-Item1-Item2','Preference']]\n",
    "for idx in range(userID.shape[0]):\n",
    "    entry = str(int(userID[idx]))+'-'+str(int(item1[idx]))+'-'+str(int(item2[idx]))\n",
    "    if(user_preference_item1[idx]>=user_preference_item2[idx]):\n",
    "        value=0\n",
    "    else:\n",
    "        value=1\n",
    "    test_output.append([entry,value])\n",
    "print(test_output)\n",
    "np.savetxt(\"output.csv\", np.array(test_output, dtype=np.str), fmt='%s,%s', delimiter=\",\")\n",
    "# print(X_test.shape)\n",
    "# print(X_test.astype(float))\n",
    "# for idx, label in enumerate(labels):\n",
    "# #     print(user_preference[userID[idx]*item1[idx]-1])\n",
    "# #     print(user_preference[userID[idx]*item2[idx]-1])\n",
    "#     if(label==0 and (user_preference[userID[idx]*item1[idx]-1]>=user_preference[userID[idx]*item2[idx]-1])):\n",
    "#         hit+=1\n",
    "#     elif(label==1 and (user_preference[userID[idx]*item1[idx]-1]<=user_preference[userID[idx]*item2[idx]-1])):\n",
    "#         hit+=1\n",
    "        \n",
    "# test_output=[['User-Item1-Item2','Preference']]\n",
    "# for idx in range(pridict_output.shape[0]):\n",
    "#     entry = str(int(userID[idx]))+'-'+str(int(item1[idx]))+'-'+str(int(item2[idx]))\n",
    "#     value = pridict_output[idx]\n",
    "#     test_output.append([entry,value])\n",
    "\n",
    "# print(test_output)\n",
    "# np.savetxt(\"output.csv\", np.array(test_output, dtype=np.str), fmt='%s,%s', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-virtualenv-tensorflow",
   "language": "python",
   "name": "my-virtualenv-tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
