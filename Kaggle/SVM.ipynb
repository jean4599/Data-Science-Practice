{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean/tensorflow/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.svm import SVC         \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pandas import DataFrame\n",
    "\n",
    "def loadTrainFile():\n",
    "    tmp = np.loadtxt(\"train.csv\", dtype=np.str, delimiter=\",\")\n",
    "    userID = tmp[1:,0].astype(int)\n",
    "    item1 = tmp[1:,1].astype(int)\n",
    "    item2 = tmp[1:,2].astype(int)\n",
    "    labels = tmp[1:,3].astype(int)\n",
    "    return userID, item1, item2, labels\n",
    "def loadTestFile():\n",
    "    tmp = np.loadtxt(\"test.csv\", dtype=np.str, delimiter=\",\")\n",
    "    userID = tmp[1:,0].astype(int)\n",
    "    item1 = tmp[1:,1].astype(int)\n",
    "    item2 = tmp[1:,2].astype(int)\n",
    "    return userID, item1, item2\n",
    "def loadUserFile():\n",
    "    tmp = np.loadtxt(\"users.csv\", dtype=str, delimiter=\",\")\n",
    "    return tmp[1:,1:]\n",
    "\n",
    "def loadItemFile():\n",
    "    tmp = np.loadtxt(\"items.csv\", dtype=np.str, delimiter=\",\")\n",
    "    return tmp[1:,1:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.72166713  1.47393266  0.97112381 ... -1.22474487 -1.28527737\n",
      "   0.81649658]\n",
      " [ 0.72166713  1.47393266  0.97112381 ...  0.81649658  1.33773767\n",
      "  -1.22474487]\n",
      " [ 0.72166713  1.47393266  0.97112381 ... -1.22474487  0.46339932\n",
      "   0.81649658]\n",
      " ...\n",
      " [ 0.72166713 -0.34948919  0.97112381 ...  0.81649658 -1.28527737\n",
      "  -1.22474487]\n",
      " [ 0.72166713 -0.34948919  0.97112381 ...  0.81649658 -0.41093902\n",
      "   0.81649658]\n",
      " [ 0.72166713 -0.34948919  0.97112381 ...  0.81649658  0.46339932\n",
      "   0.81649658]]\n",
      "[-0.19324699 -0.83740361  1.73922289  0.45090964  1.09506626 -0.83740361\n",
      " -1.48156024 -0.83740361 -0.19324699  1.09506626  0.37907125 -0.16245911\n",
      "  1.46213197 -0.70398947 -0.70398947 -0.70398947  2.00366234 -0.70398947\n",
      "  0.37907125 -1.24551983 -0.60547036  1.25751537 -0.13972393 -0.60547036\n",
      " -1.0712168   0.3260225   2.18900823  0.3260225  -0.60547036 -1.0712168\n",
      "  0.41758499 -0.77551498  2.20723495  0.41758499  0.41758499 -1.37206497\n",
      " -0.178965   -1.37206497  0.41758499 -0.178965   -0.22298824  0.5203059\n",
      "  0.5203059  -1.70957654  1.26360005  0.5203059  -0.22298824  1.26360005\n",
      " -0.22298824 -1.70957654  0.49374193 -0.9169493   1.90443316 -0.21160368\n",
      "  1.19908755 -0.21160368 -1.62229492 -0.9169493  -0.21160368  0.49374193\n",
      " -0.16744367 -0.72558924  2.06513862  0.3907019   0.94884747 -1.28373482\n",
      "  0.3907019  -1.28373482  0.3907019  -0.72558924  0.47087096 -0.87447463\n",
      " -0.20180184 -0.87447463  1.81621654  0.47087096 -0.87447463  1.14354375\n",
      " -1.54714743  0.47087096 -0.17149859  0.68599434  0.68599434  0.68599434\n",
      "  0.68599434 -1.02899151 -1.02899151 -1.88648444 -0.17149859  1.54348727\n",
      " -0.15789474  1.94736842 -1.21052632 -1.21052632 -0.15789474  0.36842105\n",
      "  0.89473684  0.89473684 -1.21052632 -0.15789474  0.3907019   0.94884747\n",
      " -0.72558924 -1.28373482 -0.72558924  0.94884747  1.50699304  0.94884747\n",
      " -1.28373482 -0.72558924 -0.18569534  1.05227358  0.43328912 -1.42366426\n",
      " -0.18569534 -0.8046798   2.2902425  -0.18569534 -0.8046798  -0.18569534\n",
      " -0.72558924 -0.16744367  2.06513862  0.3907019   0.3907019  -1.28373482\n",
      "  0.94884747 -1.28373482  0.3907019  -0.72558924 -0.61885275  0.4125685\n",
      "  1.44398974 -0.10314212 -0.61885275 -1.13456337  1.95970037 -1.13456337\n",
      "  0.4125685  -0.61885275  1.09506626 -1.48156024  1.73922289 -0.19324699\n",
      "  1.09506626 -0.83740361 -0.83740361 -0.19324699 -0.83740361  0.45090964\n",
      "  0.58950634  0.58950634  1.43165827 -0.25264558  1.43165827 -0.25264558\n",
      " -0.25264558 -0.25264558 -1.93694942 -1.0947975  -0.17291713 -0.74930754\n",
      "  2.13264455  0.40347329  0.97986371 -1.32569796 -0.17291713 -1.32569796\n",
      " -0.17291713  0.40347329 -0.72558924 -0.16744367  2.06513862  0.3907019\n",
      "  0.94884747 -1.28373482  0.3907019  -1.28373482  0.3907019  -0.72558924\n",
      " -0.15369466 -1.1783257   1.89556742  0.35862086  0.87093638 -1.1783257\n",
      "  0.87093638 -1.1783257   0.35862086 -0.66601018  1.26360005 -0.96628239\n",
      "  1.26360005 -0.22298824  1.26360005 -0.22298824 -0.22298824  0.5203059\n",
      " -1.70957654 -0.96628239 -0.15789474  1.42105263 -0.68421053 -1.21052632\n",
      " -0.68421053  0.89473684  1.42105263  0.89473684 -1.21052632 -0.68421053\n",
      " -0.83740361 -0.19324699  2.38337952  0.45090964  0.45090964 -0.83740361\n",
      " -0.19324699 -1.48156024 -0.19324699  0.45090964  1.14354375 -0.20180184\n",
      " -0.20180184 -0.87447463  1.14354375  0.47087096 -1.54714743  1.14354375\n",
      " -1.54714743  0.47087096 -0.16744367 -0.72558924  2.06513862  0.3907019\n",
      "  0.94884747 -1.28373482  0.3907019  -1.28373482  0.3907019  -0.72558924\n",
      "  0.45090964 -0.83740361  2.38337952  0.45090964  0.45090964 -1.48156024\n",
      " -0.19324699 -0.83740361 -0.19324699 -0.19324699  0.36842105 -1.21052632\n",
      "  1.94736842  0.36842105  0.36842105 -0.68421053  0.89473684 -1.21052632\n",
      "  0.36842105 -1.21052632  1.26360005 -0.96628239 -0.96628239 -0.96628239\n",
      "  0.5203059   1.26360005 -0.96628239  1.26360005 -0.96628239  0.5203059\n",
      " -0.61904762  0.80952381  0.80952381 -0.14285714 -1.0952381  -0.61904762\n",
      "  2.23809524 -1.0952381   0.33333333 -0.61904762 -1.37206497  1.61068496\n",
      "  1.01413498  0.41758499 -0.178965   -0.77551498  0.41758499 -1.37206497\n",
      " -0.77551498  1.01413498 -0.13018891 -0.13018891 -0.78113347 -1.43207802\n",
      "  1.82264475  0.52075564  1.1717002  -0.13018891  0.52075564 -1.43207802\n",
      "  1.19908755 -1.62229492  1.90443316 -0.9169493   0.49374193 -0.9169493\n",
      " -0.21160368 -0.21160368 -0.21160368  0.49374193 -0.69748583 -0.11624764\n",
      "  1.62746694  0.46499055  1.62746694 -1.27872403 -0.11624764 -1.27872403\n",
      " -0.69748583  0.46499055 -0.58079717  0.75950399  1.20627104 -0.13403012\n",
      " -1.02756422 -0.13403012  2.09980514 -1.02756422 -0.13403012 -1.02756422\n",
      " -0.12038585 -0.72231512  2.28733121 -0.12038585  0.48154341 -0.72231512\n",
      "  1.08347268 -0.72231512 -0.12038585 -1.32424438  0.57142857 -1.57142857\n",
      "  1.28571429 -0.14285714  1.28571429  0.57142857 -0.14285714  0.57142857\n",
      " -1.57142857 -0.85714286 -0.17291713 -0.74930754  2.13264455  0.40347329\n",
      "  0.97986371 -1.32569796 -0.17291713 -1.32569796  0.40347329 -0.17291713\n",
      " -0.13678823  1.23109403 -1.04870973 -1.04870973 -0.59274898  0.31917253\n",
      "  2.14301554  0.31917253 -1.04870973 -0.13678823  0.41758499 -0.77551498\n",
      "  2.20723495  0.41758499  0.41758499 -1.37206497 -0.178965   -1.37206497\n",
      "  0.41758499 -0.178965    0.3907019  -1.28373482  2.06513862  0.3907019\n",
      "  0.3907019  -1.28373482  0.3907019  -1.28373482  0.3907019  -0.16744367\n",
      "  1.05227358 -1.42366426  1.67125804 -0.18569534  1.05227358 -1.42366426\n",
      " -0.18569534 -0.8046798   0.43328912 -0.18569534 -0.18569534  0.43328912\n",
      "  2.2902425   0.43328912  0.43328912 -0.8046798  -0.8046798  -0.8046798\n",
      " -1.42366426  0.43328912 -0.64918902  0.84893949  1.84769183  0.34956332\n",
      " -0.64918902 -1.14856519  1.34831566 -1.14856519 -0.14981285 -0.64918902\n",
      "  1.09506626 -1.48156024  1.73922289 -0.19324699  1.09506626 -0.83740361\n",
      " -0.83740361 -0.83740361 -0.19324699  0.45090964  0.3907019   0.94884747\n",
      " -1.28373482 -1.28373482 -0.72558924  0.94884747  1.50699304  0.94884747\n",
      " -0.72558924 -0.72558924 -0.05882353  1.11764706 -0.64705882  0.52941176\n",
      " -1.23529412 -1.23529412  0.52941176  0.52941176  1.70588235 -1.23529412\n",
      "  1.33978769 -1.81265393  0.55167728 -1.02454353  1.33978769 -0.23643312\n",
      " -1.02454353  0.55167728  0.55167728 -0.23643312  1.09506626 -0.83740361\n",
      "  1.09506626 -0.83740361  1.09506626 -0.83740361 -1.48156024  1.09506626\n",
      " -0.83740361  0.45090964 -0.57469577 -0.57469577  2.29878308 -0.57469577\n",
      " -0.09578263 -1.05360891  0.86204366 -1.05360891  0.86204366 -0.09578263\n",
      "  0.41758499  1.01413498 -1.37206497 -1.37206497 -0.77551498  0.41758499\n",
      "  1.61068496  1.01413498 -0.178965   -0.77551498  0.          1.34839972\n",
      "  0.67419986  1.34839972  0.         -1.34839972  0.67419986 -1.34839972\n",
      "  0.         -1.34839972  0.94884747 -1.28373482  2.06513862 -0.72558924\n",
      "  0.3907019  -0.72558924  0.3907019   0.3907019  -0.16744367 -1.28373482\n",
      "  1.14354375 -0.87447463  1.81621654 -0.20180184  1.14354375 -0.20180184\n",
      " -0.87447463 -0.20180184 -1.54714743 -0.20180184  0.41758499 -1.37206497\n",
      "  2.20723495  0.41758499  0.41758499 -1.37206497 -0.178965   -0.77551498\n",
      "  0.41758499 -0.178965   -0.23643312 -1.02454353  1.33978769  0.55167728\n",
      "  1.33978769 -1.02454353 -1.02454353 -1.02454353 -0.23643312  1.33978769\n",
      " -0.16744367 -0.72558924  2.06513862  0.3907019   0.94884747 -1.28373482\n",
      "  0.3907019  -1.28373482  0.3907019  -0.72558924 -0.77551498 -0.77551498\n",
      "  2.20723495  0.41758499  1.01413498 -0.77551498 -0.178965   -1.37206497\n",
      "  0.41758499 -0.178965   -0.63599873  0.42399915  0.42399915 -1.16599767\n",
      " -1.16599767  0.42399915  2.01399597  0.95399809 -0.10599979 -1.16599767\n",
      " -0.14285714 -0.14285714  0.57142857 -0.14285714  2.71428571 -0.14285714\n",
      " -0.85714286 -0.14285714 -0.85714286 -0.85714286 -0.09805807 -0.09805807\n",
      " -1.07863874 -1.07863874  0.39223227  0.88252261 -0.09805807  2.35339362\n",
      " -1.07863874 -0.09805807 -0.75       -0.125       0.5         0.5\n",
      " -1.375      -0.75        2.375      -0.125       0.5        -0.75      ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean/tensorflow/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by the scale function.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "########### Data ###########\n",
    "user_dic = loadUserFile()\n",
    "item_dic = loadItemFile()\n",
    "userID, item1, item2, labels = loadTrainFile()\n",
    "\n",
    "preference = np.zeros([len(user_dic),10], dtype=int)\n",
    "\n",
    "for idx, label in enumerate(labels):\n",
    "    if(label==0):\n",
    "        preference[userID[idx]-1][item1[idx]-1]+=1\n",
    "#         preference[userID[idx]-1][item2[idx]-1]-=1\n",
    "    else:\n",
    "#         preference[userID[idx]-1][item1[idx]-1]-=1\n",
    "        preference[userID[idx]-1][item2[idx]-1]+=1\n",
    "\n",
    "preference = preprocessing.scale(preference, axis=1, copy=False)\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(len(user_dic)):\n",
    "    for j in range(len(item_dic)):\n",
    "        X_train.append(np.concatenate([user_dic[i].astype(float),item_dic[j].astype(float)]))\n",
    "        y_train.append(preference[i][j])\n",
    "X_train = np.array(X_train)\n",
    "X_train = preprocessing.scale(X_train, axis=0, copy=False)\n",
    "y_train = np.array(y_train).reshape(len(y_train))\n",
    "print(X_train)\n",
    "print(y_train)\n",
    "########### Data ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean/tensorflow/lib/python3.6/site-packages/scipy/linalg/basic.py:1226: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1364\n",
      "hit %:  0.6407624633431085\n"
     ]
    }
   ],
   "source": [
    "########### Model ###########\n",
    "\n",
    "# # Split data into training data and testing data\n",
    "X_train_fold, X_test_fold, y_train_fold, y_test_fold = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n",
    "\n",
    "linearRegres = LinearRegression()\n",
    "linearRegres.fit(X_train_fold,y_train_fold)\n",
    "\n",
    "########## Validate ##########\n",
    "hit = 0\n",
    "\n",
    "X_train_item1 = np.concatenate([user_dic[userID-1].astype(float), item_dic[item1-1].astype(float)], axis=1)\n",
    "X_train_item2 = np.concatenate([user_dic[userID-1].astype(float), item_dic[item2-1].astype(float)], axis=1)\n",
    "X_train_item1 = preprocessing.scale(X_train_item1, axis=0, copy=False)\n",
    "X_train_item2 = preprocessing.scale(X_train_item2, axis=0, copy=False)\n",
    "user_preference_item1 = linearRegres.predict(X_train_item1)\n",
    "user_preference_item2 = linearRegres.predict(X_train_item2)\n",
    "\n",
    "for idx in range(userID.shape[0]):\n",
    "    entry = str(int(userID[idx]))+'-'+str(int(item1[idx]))+'-'+str(int(item2[idx]))\n",
    "    if(labels[idx]==0 and user_preference_item1[idx]>=user_preference_item2[idx]):\n",
    "        hit+=1\n",
    "    elif(labels[idx]==1 and user_preference_item1[idx]<user_preference_item2[idx]):\n",
    "        hit+=1\n",
    "print(userID.shape[0])\n",
    "\n",
    "print(\"hit %: \" , hit/userID.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.72166713  1.47393266  0.97112381 ...  0.81649658 -0.41093902\n",
      "   0.81649658]\n",
      " [-3.21469902 -0.34948919 -2.78806513 ...  0.81649658  0.46339932\n",
      "   0.81649658]\n",
      " [ 0.72166713  0.56222174 -0.90847066 ...  0.81649658 -0.41093902\n",
      "  -1.22474487]\n",
      " ...\n",
      " [ 0.72166713 -0.34948919 -0.90847066 ...  0.81649658  0.46339932\n",
      "   0.81649658]\n",
      " [ 0.72166713  0.56222174  0.97112381 ... -1.22474487  0.46339932\n",
      "   0.81649658]\n",
      " [ 0.72166713  1.47393266  0.97112381 ...  0.81649658  0.46339932\n",
      "   0.81649658]]\n",
      "[-1.57142857 -1.34839972  2.14301554 -0.70398947 -1.28373482 -0.09805807\n",
      " -1.21052632 -0.12038585 -0.15789474 -0.83740361 -0.14285714  1.62746694\n",
      " -0.58079717  1.26360005 -0.72558924  1.90443316  0.97986371 -0.19324699\n",
      " -0.83740361 -1.32569796 -0.70398947 -0.72558924  1.25751537 -1.28373482\n",
      " -1.48156024  0.3907019  -0.96628239 -1.1783257  -1.37206497 -0.77551498\n",
      "  1.01413498  2.06513862  0.80952381  1.28571429 -0.63599873  0.52941176\n",
      "  0.36842105 -0.14285714  0.43328912 -1.37206497  0.45090964  0.3907019\n",
      "  0.41758499  0.86204366  0.94884747 -0.20180184 -0.17291713 -0.85714286\n",
      "  0.41758499 -1.07863874 -0.83740361 -0.68421053  1.46213197  1.33978769\n",
      " -0.19324699  0.49374193 -0.77551498 -1.54714743  0.3907019   1.73922289\n",
      "  1.09506626 -0.14285714 -1.16599767  1.42105263 -0.64918902 -0.21160368\n",
      "  1.50699304 -0.70398947 -0.19324699  0.5203059  -1.48156024  0.5203059\n",
      " -0.14981285 -0.96628239  0.47087096  0.37907125 -0.72558924 -0.83740361\n",
      " -0.14285714 -0.178965    0.40347329 -1.28373482  0.48154341 -0.72558924\n",
      " -0.75        1.09506626  0.3907019   0.94884747  0.46499055 -0.57469577\n",
      " -0.8046798  -1.04870973 -0.21160368 -0.15789474  1.05227358  1.67125804\n",
      " -1.37206497 -0.72558924 -0.125      -0.57469577  0.47087096  0.3907019\n",
      "  0.3907019  -0.69748583  1.44398974  1.01413498  0.80952381  2.38337952\n",
      " -1.28373482 -0.20180184  2.06513862 -0.72558924  0.89473684 -0.83740361\n",
      "  0.41758499  0.5         1.54348727  2.06513862 -1.42366426 -0.25264558\n",
      " -0.22298824 -0.96628239  0.55167728 -0.16744367  0.94884747  0.3907019\n",
      "  2.20723495 -0.19324699 -0.22298824 -0.87447463 -1.32569796 -0.72558924\n",
      " -0.18569534 -1.28373482 -0.09805807 -1.28373482 -0.23643312  0.57142857\n",
      " -0.8046798   0.31917253 -0.83740361  1.09506626  2.18900823  0.45090964\n",
      " -1.28373482 -0.19324699 -1.32569796 -0.23643312  1.34839972 -0.61885275\n",
      "  0.41758499 -0.09805807  0.52941176  1.94736842  0.42399915  0.67419986\n",
      " -0.22298824  1.23109403 -0.96628239  1.09506626 -1.37206497 -0.16744367\n",
      "  0.52075564 -1.42366426  0.37907125 -0.87447463  0.47087096 -0.75\n",
      " -0.72231512 -1.42366426  0.35862086  2.375       2.28733121  1.28571429\n",
      " -1.0947975  -0.77551498 -0.12038585  1.08347268  0.43328912 -0.8046798\n",
      " -1.28373482  0.43328912 -0.96628239  0.3907019  -0.13678823  0.45090964\n",
      " -1.28373482  0.94884747  0.94884747  0.          0.55167728 -1.42366426\n",
      "  2.2902425  -0.69748583 -1.62229492  0.5         0.3907019  -0.8046798\n",
      " -1.13456337 -0.12038585 -0.83740361  1.09506626 -0.72558924  2.20723495\n",
      "  2.06513862  0.39223227 -1.23529412  0.45090964 -0.25264558 -1.32424438\n",
      " -1.1783257   0.94884747  0.89473684 -0.60547036 -0.25264558  1.19908755\n",
      "  0.41758499  0.49374193 -1.70957654  0.3907019   0.3907019   1.01413498\n",
      " -0.11624764 -0.18569534  0.45090964 -0.74930754 -1.62229492 -0.16744367\n",
      "  1.33978769 -0.61904762 -1.43207802 -1.21052632 -0.9169493  -0.77551498\n",
      " -1.32569796  0.41758499 -0.13403012  0.46499055 -0.20180184  0.40347329\n",
      "  0.3907019   1.43165827  0.49374193 -0.09578263  0.42399915  0.33333333\n",
      " -1.93694942 -0.9169493  -0.83740361 -0.17291713  0.45090964  1.81621654\n",
      "  1.09506626 -0.83740361 -1.28373482 -0.11624764  0.41758499 -0.83740361\n",
      " -1.48156024 -0.178965   -1.13456337 -1.02756422 -0.16744367 -0.13972393\n",
      "  2.23809524 -0.178965   -0.57469577 -0.14285714  1.61068496  1.14354375\n",
      "  0.3907019  -0.72558924  0.68599434  1.11764706 -0.21160368  0.88252261\n",
      " -0.85714286 -0.17291713 -1.07863874  0.3907019  -0.05882353  1.01413498\n",
      " -0.8046798  -0.22298824 -0.96628239  2.2902425   1.73922289 -0.77551498\n",
      "  0.97986371  1.50699304 -1.48156024  0.3907019   0.94884747 -1.02454353\n",
      " -0.10599979 -0.178965    0.5        -1.21052632 -0.16744367  0.86204366\n",
      "  1.84769183  0.94884747 -1.70957654 -0.83740361  0.58950634 -0.178965\n",
      " -0.72558924  0.43328912  1.20627104  0.36842105 -0.178965   -0.72558924\n",
      "  1.73922289  0.57142857 -0.20180184  0.42399915 -0.83740361  1.01413498\n",
      " -0.83740361  1.05227358  0.         -0.18569534 -0.125      -1.05360891\n",
      " -1.02454353  0.3907019   1.33978769 -0.17291713  0.57142857 -1.14856519\n",
      " -1.54714743 -0.19324699 -1.14856519  1.95970037  0.3907019   0.36842105\n",
      " -0.64918902 -1.37206497  0.55167728  1.14354375 -0.68421053  2.06513862\n",
      " -0.10314212  0.41758499 -0.17149859 -0.13018891  1.26360005  0.40347329\n",
      " -1.57142857 -0.72558924 -0.96628239  0.43328912 -0.85714286  0.41758499\n",
      "  1.09506626 -0.59274898 -0.19324699  1.90443316 -1.02454353 -0.13018891\n",
      " -0.87447463  0.52075564 -1.37206497 -1.48156024 -1.0712168  -0.20180184\n",
      " -1.28373482 -0.16744367  0.49374193  0.57142857 -1.48156024  0.3260225\n",
      "  1.34839972 -0.09805807 -0.25264558  0.67419986 -0.72558924  0.4125685\n",
      "  2.38337952 -0.72558924 -0.14285714  0.3907019  -0.77551498 -0.83740361\n",
      "  1.33978769 -0.66601018  0.45090964  0.41758499 -0.68421053  0.94884747\n",
      " -1.21052632 -1.28373482 -1.0712168  -1.28373482 -0.19324699  1.19908755\n",
      " -1.02454353 -0.87447463 -0.72558924 -0.85714286  1.05227358 -0.17291713\n",
      "  1.26360005  0.89473684 -0.22298824 -1.0952381  -0.87447463  0.47087096\n",
      "  1.09506626  1.09506626 -1.02756422 -0.70398947 -1.37206497  2.09980514\n",
      " -0.16744367 -1.21052632 -1.54714743  1.34831566 -0.87447463 -0.74930754\n",
      "  0.68599434 -1.23529412 -0.18569534  0.41758499 -0.83740361 -1.34839972\n",
      "  0.3260225  -0.18569534  0.45090964  0.34956332  1.43165827  2.00366234\n",
      "  0.         -0.72231512 -0.72558924  2.20723495 -0.83740361 -0.20180184\n",
      " -0.61885275 -1.28373482 -1.81265393  1.26360005  2.13264455 -0.61904762\n",
      " -1.27872403 -0.13403012  2.06513862 -0.19324699  1.33978769 -0.64918902\n",
      " -1.37206497 -1.02454353 -1.24551983 -0.13403012  1.1717002  -0.23643312\n",
      "  0.5203059  -1.04870973 -1.54714743 -0.15789474  0.45090964 -1.28373482\n",
      " -1.28373482 -1.37206497  0.41758499  1.14354375 -1.16599767 -1.23529412\n",
      "  0.87093638 -0.77551498 -0.75        2.35339362 -0.61904762  1.82264475\n",
      "  2.01399597  1.89556742  2.20723495 -0.17149859 -0.21160368  0.36842105\n",
      " -0.16245911 -0.13678823 -1.70957654 -1.02899151 -0.178965   -0.21160368\n",
      "  0.5203059   0.84893949 -0.68421053 -0.83740361  0.3907019  -1.21052632\n",
      " -1.37206497 -0.61885275 -0.60547036  0.41758499  0.41758499  1.81621654\n",
      "  0.3907019   1.42105263 -1.04870973 -1.28373482 -0.78113347  0.89473684\n",
      "  0.5203059   0.36842105 -1.07863874  0.40347329 -0.9169493   0.41758499\n",
      "  1.14354375 -0.19324699 -0.15369466  0.4125685   1.26360005 -1.02756422\n",
      " -1.21052632  0.68599434  0.43328912  1.94736842  0.68599434  0.3907019\n",
      " -0.18569534 -0.13018891 -0.9169493   0.75950399 -1.21052632  2.71428571\n",
      " -0.64705882  0.5203059   0.3907019  -0.72231512 -0.14285714 -0.178965\n",
      " -0.77551498 -0.21160368  0.95399809  0.3907019  -0.60547036  0.35862086\n",
      " -0.23643312  1.14354375  0.58950634  0.45090964  0.3907019   0.94884747\n",
      "  1.26360005 -0.77551498 -0.19324699 -0.19324699 -1.28373482 -0.15789474\n",
      "  1.70588235  0.94884747 -0.8046798  -0.20180184 -1.02454353  0.94884747\n",
      " -1.88648444 -0.77551498  1.61068496  1.62746694 -0.18569534  2.29878308\n",
      "  0.47087096 -1.0952381   1.09506626 -0.17291713  1.26360005 -0.178965  ]\n",
      "1364\n",
      "hit %:  0.6414956011730205\n"
     ]
    }
   ],
   "source": [
    "########### Model ###########\n",
    "\n",
    "# # Split data into training data and testing data\n",
    "X_train_fold, X_test_fold, y_train_fold, y_test_fold = train_test_split(X_train, y_train, test_size=0.05, random_state=0)\n",
    "\n",
    "ridge = Ridge(alpha = .1)\n",
    "ridge.fit(X_train_fold,y_train_fold)\n",
    "print(X_train_fold)\n",
    "print(y_train_fold)\n",
    "########## Validate ##########\n",
    "hit = 0\n",
    "\n",
    "X_train_item1 = np.concatenate([user_dic[userID-1].astype(float), item_dic[item1-1].astype(float)], axis=1)\n",
    "X_train_item2 = np.concatenate([user_dic[userID-1].astype(float), item_dic[item2-1].astype(float)], axis=1)\n",
    "X_train_item1 = preprocessing.scale(X_train_item1, axis=0, copy=False)\n",
    "X_train_item2 = preprocessing.scale(X_train_item2, axis=0, copy=False)\n",
    "# print(X_train_item1)\n",
    "# print(X_train_item2)\n",
    "user_preference_item1 = ridge.predict(X_train_item1)\n",
    "user_preference_item2 = ridge.predict(X_train_item2)\n",
    "\n",
    "for idx in range(userID.shape[0]):\n",
    "    entry = str(int(userID[idx]))+'-'+str(int(item1[idx]))+'-'+str(int(item2[idx]))\n",
    "    if(labels[idx]==0 and user_preference_item1[idx]>user_preference_item2[idx]):\n",
    "        hit+=1\n",
    "    elif(labels[idx]==1 and user_preference_item1[idx]<=user_preference_item2[idx]):\n",
    "        hit+=1\n",
    "print(userID.shape[0])\n",
    "\n",
    "print(\"hit %: \" , hit/userID.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## Test ##########\n",
    "print(\"########## Start Test ##########\")\n",
    "\n",
    "userID, item1, item2 = loadTestFile()\n",
    "\n",
    "X_test_item1 = np.concatenate([user_dic[userID-1].astype(float), item_dic[item1-1].astype(float)], axis=1)\n",
    "X_test_item2 = np.concatenate([user_dic[userID-1].astype(float), item_dic[item2-1].astype(float)], axis=1)\n",
    "user_preference_item1 = svm.predict(X_test_item1)\n",
    "user_preference_item2 = svm.predict(X_test_item2)\n",
    "\n",
    "test_output=[['User-Item1-Item2','Preference']]\n",
    "for idx in range(userID.shape[0]):\n",
    "    entry = str(int(userID[idx]))+'-'+str(int(item1[idx]))+'-'+str(int(item2[idx]))\n",
    "    if(user_preference_item1[idx]>=user_preference_item2[idx]):\n",
    "        value=0\n",
    "    else:\n",
    "        value=1\n",
    "    test_output.append([entry,value])\n",
    "print(test_output)\n",
    "np.savetxt(\"output.csv\", np.array(test_output, dtype=np.str), fmt='%s,%s', delimiter=\",\")\n",
    "# print(X_test.shape)\n",
    "# print(X_test.astype(float))\n",
    "# for idx, label in enumerate(labels):\n",
    "# #     print(user_preference[userID[idx]*item1[idx]-1])\n",
    "# #     print(user_preference[userID[idx]*item2[idx]-1])\n",
    "#     if(label==0 and (user_preference[userID[idx]*item1[idx]-1]>=user_preference[userID[idx]*item2[idx]-1])):\n",
    "#         hit+=1\n",
    "#     elif(label==1 and (user_preference[userID[idx]*item1[idx]-1]<=user_preference[userID[idx]*item2[idx]-1])):\n",
    "#         hit+=1\n",
    "        \n",
    "# test_output=[['User-Item1-Item2','Preference']]\n",
    "# for idx in range(pridict_output.shape[0]):\n",
    "#     entry = str(int(userID[idx]))+'-'+str(int(item1[idx]))+'-'+str(int(item2[idx]))\n",
    "#     value = pridict_output[idx]\n",
    "#     test_output.append([entry,value])\n",
    "\n",
    "# print(test_output)\n",
    "# np.savetxt(\"output.csv\", np.array(test_output, dtype=np.str), fmt='%s,%s', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-virtualenv-tensorflow",
   "language": "python",
   "name": "my-virtualenv-tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
